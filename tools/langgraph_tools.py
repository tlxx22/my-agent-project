"""
LangGraphæ ‡å‡†å·¥å…·å®šä¹‰
ä½¿ç”¨@toolè£…é¥°å™¨å®šä¹‰æ‰€æœ‰å·¥å…·å‡½æ•°
"""
from typing import List, Dict, Any, Optional
import pandas as pd
from langchain_core.tools import tool
import logging

# å¯¼å…¥åŸæœ‰åŠŸèƒ½æ¨¡å—
from .extract_excel_tables import extract_excel_tables as _extract_excel_tables
from .parse_instrument_table import extract_instrument_info as _extract_instrument_info, validate_parsed_data
from .classify_instrument_type import classify_instrument_type
from .summarize_statistics import summarize_statistics as _summarize_statistics, generate_summary_report, get_summary_statistics
from .enhanced_rag_retriever import EnhancedRAGRetriever
from .generate_installation_recommendation import InstallationRecommendationGenerator

logger = logging.getLogger(__name__)

# å…¨å±€å®ä¾‹
_retriever = None
_recommendation_generator = None

def get_retriever():
    """è·å–å¢å¼ºæ£€ç´¢å™¨å®ä¾‹"""
    global _retriever
    if _retriever is None:
        _retriever = EnhancedRAGRetriever()
        logger.info("ğŸš€ LangGraphå·¥å…·é›†å·²åˆ‡æ¢ä¸ºå¢å¼ºæ£€ç´¢å™¨")
    return _retriever

def get_recommendation_generator():
    """è·å–æ¨èç”Ÿæˆå™¨å®ä¾‹"""
    global _recommendation_generator
    if _recommendation_generator is None:
        _recommendation_generator = InstallationRecommendationGenerator()
    return _recommendation_generator

@tool
def extract_excel_tables(file_path: str, keyword: str = "ä»ªè¡¨æ¸…å•") -> Dict[str, Any]:
    """
    ä»Excelæ–‡ä»¶ä¸­æå–åŒ…å«æŒ‡å®šå…³é”®å­—çš„è¡¨æ ¼æ•°æ®
    
    Args:
        file_path: Excelæ–‡ä»¶è·¯å¾„
        keyword: è¯†åˆ«å…³é”®å­—ï¼Œé»˜è®¤ä¸º"ä»ªè¡¨æ¸…å•"
    
    Returns:
        åŒ…å«æå–ç»“æœçš„å­—å…¸ï¼š{"success": bool, "tables": List[Dict], "message": str}
    """
    try:
        tables = _extract_excel_tables(file_path, keyword)
        
        if not tables:
            # å°è¯•å…¶ä»–å…³é”®å­—
            for alt_keyword in ["ä»ªè¡¨", "è®¾å¤‡æ¸…å•", "ææ–™è¡¨"]:
                tables = _extract_excel_tables(file_path, alt_keyword)
                if tables:
                    break
        
        if tables:
            return {
                "success": True,
                "tables": tables,
                "message": f"æˆåŠŸæå– {len(tables)} ä¸ªè¡¨æ ¼"
            }
        else:
            return {
                "success": False,
                "tables": [],
                "message": "æœªåœ¨Excelæ–‡ä»¶ä¸­æ‰¾åˆ°ä»ªè¡¨ç›¸å…³è¡¨æ ¼"
            }
            
    except Exception as e:
        logger.error(f"æå–è¡¨æ ¼å¤±è´¥: {str(e)}")
        return {
            "success": False,
            "tables": [],
            "message": f"æå–è¡¨æ ¼å¤±è´¥: {str(e)}"
        }

@tool
def parse_instrument_table(table_data: Dict) -> Dict[str, Any]:
    """
    è§£æä»ªè¡¨è¡¨æ ¼æ•°æ®ï¼Œæå–å‹å·ã€æ•°é‡ç­‰ä¿¡æ¯
    
    Args:
        table_data: è¡¨æ ¼æ•°æ®å­—å…¸ï¼ŒåŒ…å«dataå­—æ®µï¼ˆpandas DataFrameï¼‰
    
    Returns:
        è§£æç»“æœå­—å…¸ï¼š{"success": bool, "parsed_data": Dict, "message": str}
    """
    try:
        if "data" not in table_data:
            raise ValueError("è¡¨æ ¼æ•°æ®ä¸­ç¼ºå°‘dataå­—æ®µ")
        
        df = table_data["data"]
        
        # è§£æä»ªè¡¨ä¿¡æ¯
        parsed_df = _extract_instrument_info(df)
        
        # éªŒè¯è§£æç»“æœ
        if not validate_parsed_data(parsed_df):
            raise ValueError("è§£æçš„æ•°æ®æ— æ•ˆ")
        
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ä»¥ä¾¿åºåˆ—åŒ–
        parsed_data = {
            "columns": list(parsed_df.columns),
            "data": parsed_df.to_dict('records'),
            "row_count": len(parsed_df)
        }
        
        return {
            "success": True,
            "parsed_data": parsed_data,
            "message": f"æˆåŠŸè§£æ {len(parsed_df)} è¡Œä»ªè¡¨æ•°æ®"
        }
        
    except Exception as e:
        logger.error(f"è§£æè¡¨æ ¼å¤±è´¥: {str(e)}")
        return {
            "success": False,
            "parsed_data": None,
            "message": f"è§£æè¡¨æ ¼å¤±è´¥: {str(e)}"
        }

@tool
def classify_instrument_types(parsed_data: Dict, use_llm: bool = True) -> Dict[str, Any]:
    """
    ä»ªè¡¨åˆ†ç±»è¡¥å……å¤„ç†ï¼šä»…åœ¨è¡¨æ ¼æ²¡æœ‰æ˜ç¡®åˆ†ç±»æ—¶ä½¿ç”¨LLMåˆ†ç±»
    
    é€»è¾‘è¯´æ˜ï¼š
    1. å¦‚æœè¡¨æ ¼æœ‰æ˜ç¡®åˆ†ç±»ï¼Œparse_instrument_tableå·²å®Œæˆæ‰€æœ‰åˆ†ç±»å·¥ä½œï¼Œæ­¤å‡½æ•°ç›´æ¥è¿”å›
    2. å¦‚æœè¡¨æ ¼æ²¡æœ‰åˆ†ç±»ï¼Œæ‰€æœ‰ä»ªè¡¨éƒ½æ˜¯"æœªåˆ†ç±»"ï¼Œä½¿ç”¨LLMé€ä¸ªåˆ¤æ–­
    3. LLMå¯èƒ½è¿”å›"æ— æ³•è¯†åˆ«"ï¼Œè¿™äº›ä»ªè¡¨åœ¨åç»­æ ‡å‡†åŒ¹é…ä¸­ä¼šè¢«è·³è¿‡
    
    Args:
        parsed_data: è§£æåçš„æ•°æ®å­—å…¸ï¼ˆåº”è¯¥å·²ç»åŒ…å«'ä»ªè¡¨ç±»å‹'åˆ—ï¼‰
        use_llm: æ˜¯å¦ä½¿ç”¨LLMå¯¹æœªåˆ†ç±»é¡¹è¿›è¡Œåˆ†ç±»
    
    Returns:
        åˆ†ç±»ç»“æœå­—å…¸ï¼š{"success": bool, "classified_data": Dict, "message": str}
    """
    try:
        if not parsed_data or "data" not in parsed_data:
            raise ValueError("æ— æ•ˆçš„è§£ææ•°æ®")
        
        # é‡å»ºDataFrame
        df = pd.DataFrame(parsed_data["data"])
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰åˆ†ç±»ç»“æœ
        if 'ä»ªè¡¨ç±»å‹' not in df.columns:
            logger.warning("è§£ææ•°æ®ä¸­ç¼ºå°‘'ä»ªè¡¨ç±»å‹'åˆ—ï¼Œparse_instrument_tableå¯èƒ½æœªæ­£ç¡®æ‰§è¡Œ")
            df['ä»ªè¡¨ç±»å‹'] = "æœªåˆ†ç±»"
        
        # ç»Ÿè®¡åˆ†ç±»æƒ…å†µ
        classified_count = len(df[df['ä»ªè¡¨ç±»å‹'] != "æœªåˆ†ç±»"])
        unclassified_count = len(df[df['ä»ªè¡¨ç±»å‹'] == "æœªåˆ†ç±»"])
        
        logger.info(f"åˆ†ç±»çŠ¶æ€æ£€æŸ¥: å·²åˆ†ç±» {classified_count} ä¸ªï¼Œæœªåˆ†ç±» {unclassified_count} ä¸ª")
        
        # å…³é”®é€»è¾‘ï¼šå¦‚æœæœ‰è¡¨æ ¼åˆ†ç±»ï¼Œæ‰€æœ‰ä»ªè¡¨éƒ½åº”è¯¥å·²ç»åˆ†ç±»ï¼Œç›´æ¥è¿”å›
        if classified_count > 0 and unclassified_count == 0:
            logger.info("âœ… è¡¨æ ¼å·²æœ‰å®Œæ•´åˆ†ç±»ï¼Œæ— éœ€LLMè¡¥å……åˆ†ç±»")
            classified_data = {
                "columns": list(df.columns),
                "data": df.to_dict('records'),
                "row_count": len(df)
            }
            return {
                "success": True,
                "classified_data": classified_data,
                "message": f"è¡¨æ ¼åˆ†ç±»å®Œæ•´: å…± {classified_count} ä¸ªä»ªè¡¨å·²åˆ†ç±»"
            }
        
        # åªæœ‰å½“æ‰€æœ‰ä»ªè¡¨éƒ½æœªåˆ†ç±»æ—¶ï¼Œæ‰ä½¿ç”¨LLMåˆ†ç±»ï¼ˆè¡¨æ ¼æ²¡æœ‰åˆ†ç±»æ ‡é¢˜çš„æƒ…å†µï¼‰
        if unclassified_count == len(df) and use_llm:
            logger.info(f"ğŸ¤– è¡¨æ ¼æ— åˆ†ç±»æ ‡é¢˜ï¼Œä½¿ç”¨LLMå¯¹ {unclassified_count} ä¸ªä»ªè¡¨è¿›è¡Œæ™ºèƒ½åˆ†ç±»...")
            
            # å‡†å¤‡LLMåˆ†ç±»çš„æ•°æ®
            models = df['å‹å·'].tolist()
            specs = df.get('è§„æ ¼', [''] * len(models)).tolist()
            contexts = df.get('å¤‡æ³¨', [''] * len(models)).tolist()
            
            # ä½¿ç”¨LLMé€ä¸ªåˆ†ç±»
            llm_classifications = []
            for i, (model, spec, context) in enumerate(zip(models, specs, contexts)):
                if i % 10 == 0:  # è¿›åº¦æç¤º
                    logger.info(f"LLMåˆ†ç±»è¿›åº¦: {i+1}/{len(models)}")
                
                classification = classify_instrument_type(
                    model=model,
                    spec=spec,
                    context=context,
                    row_index=-1,  # ä¸ä½¿ç”¨è¡¨æ ¼ä½ç½®ä¿¡æ¯
                    table_categories=None,  # è¡¨æ ¼æ²¡æœ‰åˆ†ç±»
                    use_llm=True
                )
                llm_classifications.append(classification)
        
            # æ›´æ–°åˆ†ç±»ç»“æœ
            df['ä»ªè¡¨ç±»å‹'] = llm_classifications
            
            # ç»Ÿè®¡LLMåˆ†ç±»çš„æ•ˆæœ
            successfully_classified = len([c for c in llm_classifications if c not in ["æœªåˆ†ç±»", "æ— æ³•è¯†åˆ«"]])
            unrecognized_count = len([c for c in llm_classifications if c == "æ— æ³•è¯†åˆ«"])
            
            logger.info(f"âœ… LLMåˆ†ç±»å®Œæˆ: æˆåŠŸåˆ†ç±» {successfully_classified} ä¸ªï¼Œæ— æ³•è¯†åˆ« {unrecognized_count} ä¸ª")
            
            message = f"LLMæ™ºèƒ½åˆ†ç±»: æˆåŠŸåˆ†ç±» {successfully_classified} ä¸ªï¼Œæ— æ³•è¯†åˆ« {unrecognized_count} ä¸ª"
        
        elif unclassified_count > 0 and classified_count > 0:
            # å¼‚å¸¸æƒ…å†µï¼šéƒ¨åˆ†åˆ†ç±»éƒ¨åˆ†æœªåˆ†ç±»ï¼Œç†è®ºä¸Šä¸åº”è¯¥å‘ç”Ÿ
            logger.warning(f"âš ï¸ å¼‚å¸¸åˆ†ç±»çŠ¶æ€: {classified_count} ä¸ªå·²åˆ†ç±»ï¼Œ{unclassified_count} ä¸ªæœªåˆ†ç±»")
            message = f"åˆ†ç±»çŠ¶æ€å¼‚å¸¸: {classified_count} ä¸ªå·²åˆ†ç±»ï¼Œ{unclassified_count} ä¸ªæœªåˆ†ç±»"
        
        else:
            # ä¸ä½¿ç”¨LLMæˆ–å…¶ä»–æƒ…å†µ
            message = f"ä¿æŒåŸæœ‰åˆ†ç±»çŠ¶æ€: {classified_count} ä¸ªå·²åˆ†ç±»ï¼Œ{unclassified_count} ä¸ªæœªåˆ†ç±»"
        
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        classified_data = {
            "columns": list(df.columns),
            "data": df.to_dict('records'),
            "row_count": len(df)
        }
        
        return {
            "success": True,
            "classified_data": classified_data,
            "message": message
        }
        
    except Exception as e:
        logger.error(f"åˆ†ç±»å¤„ç†å¤±è´¥: {str(e)}")
        return {
            "success": False,
            "classified_data": None,
            "message": f"åˆ†ç±»å¤„ç†å¤±è´¥: {str(e)}"
        }

@tool
def summarize_instrument_statistics(classified_data: Dict) -> Dict[str, Any]:
    """
    ç”Ÿæˆä»ªè¡¨ç»Ÿè®¡æ±‡æ€»
    
    Args:
        classified_data: åˆ†ç±»åçš„æ•°æ®å­—å…¸
    
    Returns:
        ç»Ÿè®¡ç»“æœå­—å…¸ï¼š{"success": bool, "summary_data": Dict, "statistics_info": Dict, "message": str}
    """
    try:
        if not classified_data or "data" not in classified_data:
            raise ValueError("æ— æ•ˆçš„åˆ†ç±»æ•°æ®")
        
        # é‡å»ºDataFrame
        df = pd.DataFrame(classified_data["data"])
        
        # ç”Ÿæˆç»Ÿè®¡æ±‡æ€»
        summary_df = _summarize_statistics(df, use_llm_classification=False)
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats_info = get_summary_statistics(summary_df)
        
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        summary_data = {
            "columns": list(summary_df.columns),
            "data": summary_df.to_dict('records'),
            "row_count": len(summary_df)
        }
        
        return {
            "success": True,
            "summary_data": summary_data,
            "statistics_info": stats_info,
            "message": f"ç»Ÿè®¡æ±‡æ€»å®Œæˆï¼Œå…± {stats_info['total_instruments']} å°ä»ªè¡¨"
        }
        
    except Exception as e:
        logger.error(f"ç»Ÿè®¡æ±‡æ€»å¤±è´¥: {str(e)}")
        return {
            "success": False,
            "summary_data": None,
            "statistics_info": None,
            "message": f"ç»Ÿè®¡æ±‡æ€»å¤±è´¥: {str(e)}"
        }

@tool
def match_installation_standards(statistics_info: Dict) -> Dict[str, Any]:
    """
    åŒ¹é…ä»ªè¡¨å®‰è£…è§„èŒƒï¼ˆè‡ªåŠ¨è·³è¿‡æ— æ³•è¯†åˆ«å’Œæœªåˆ†ç±»çš„ä»ªè¡¨ï¼‰
    
    Args:
        statistics_info: ç»Ÿè®¡ä¿¡æ¯å­—å…¸
    
    Returns:
        åŒ¹é…ç»“æœå­—å…¸ï¼š{"success": bool, "standard_clauses": Dict, "message": str}
    """
    try:
        if not statistics_info or 'type_distribution' not in statistics_info:
            raise ValueError("æ— æ•ˆçš„ç»Ÿè®¡ä¿¡æ¯")
        
        retriever = get_retriever()
        standard_clauses = {}
        skipped_types = []
        
        # ä¸ºæ¯ç§ä»ªè¡¨ç±»å‹æ£€ç´¢ç›¸å…³è§„èŒƒ
        for instrument_type, count in statistics_info['type_distribution'].items():
            # è·³è¿‡æ— æ•ˆåˆ†ç±»
            if count <= 0:
                continue
                
            # è·³è¿‡æ— æ³•è¯†åˆ«å’Œæœªåˆ†ç±»çš„ä»ªè¡¨ï¼ˆè¿™äº›ä¸éœ€è¦åŒ¹é…æ ‡å‡†ï¼‰
            if instrument_type in ["æœªçŸ¥", "æœªåˆ†ç±»", "æ— æ³•è¯†åˆ«"]:
                skipped_types.append((instrument_type, count))
                logger.info(f"â­ï¸ è·³è¿‡ {instrument_type} ä»ªè¡¨ {count} å°ï¼ˆæ— éœ€åŒ¹é…æ ‡å‡†ï¼‰")
                continue
                
            try:
                # è·å–ç»¼åˆè§„èŒƒä¿¡æ¯
                logger.info(f"ğŸ” æ­£åœ¨åŒ¹é… {instrument_type} å®‰è£…è§„èŒƒ...")
                comprehensive_info = retriever.get_comprehensive_standards(instrument_type)
                standard_clauses[instrument_type] = comprehensive_info
                logger.info(f"âœ… æˆåŠŸåŒ¹é… {instrument_type} è§„èŒƒ")
                
            except Exception as e:
                logger.warning(f"âŒ è·å– {instrument_type} è§„èŒƒå¤±è´¥: {str(e)}")
                continue
        
        # æ„å»ºç»“æœæ¶ˆæ¯
        message_parts = []
        if standard_clauses:
            message_parts.append(f"æˆåŠŸåŒ¹é… {len(standard_clauses)} ç§ä»ªè¡¨çš„å®‰è£…è§„èŒƒ")
        
        if skipped_types:
            skipped_count = sum(count for _, count in skipped_types)
            skipped_types_str = ", ".join([f"{t}({c}å°)" for t, c in skipped_types])
            message_parts.append(f"è·³è¿‡ {skipped_count} å°ä»ªè¡¨: {skipped_types_str}")
        
        message = "; ".join(message_parts) if message_parts else "æœªæ‰¾åˆ°éœ€è¦åŒ¹é…æ ‡å‡†çš„ä»ªè¡¨"
        
        return {
            "success": True,
            "standard_clauses": standard_clauses,
            "message": message
        }
        
    except Exception as e:
        logger.error(f"åŒ¹é…å®‰è£…è§„èŒƒå¤±è´¥: {str(e)}")
        return {
            "success": False,
            "standard_clauses": {},
            "message": f"åŒ¹é…å®‰è£…è§„èŒƒå¤±è´¥: {str(e)}"
        }

@tool
def generate_installation_recommendations(summary_data: Dict, statistics_info: Dict) -> Dict[str, Any]:
    """
    ç”Ÿæˆå®‰è£…æ¨èæ–¹æ¡ˆ
    
    Args:
        summary_data: æ±‡æ€»æ•°æ®å­—å…¸
        statistics_info: ç»Ÿè®¡ä¿¡æ¯å­—å…¸
    
    Returns:
        æ¨èç»“æœå­—å…¸ï¼š{"success": bool, "recommendations": Dict, "message": str}
    """
    try:
        if not summary_data or not statistics_info:
            raise ValueError("ç¼ºå°‘å¿…è¦çš„æ•°æ®")
        
        generator = get_recommendation_generator()
        recommendations = {}
        
        # é‡å»ºDataFrame
        summary_df = pd.DataFrame(summary_data["data"])
        
        # ä¸ºä¸»è¦ä»ªè¡¨ç±»å‹ç”Ÿæˆè¯¦ç»†æ¨èï¼ˆè·³è¿‡æ— æ³•è¯†åˆ«å’Œæœªåˆ†ç±»çš„ä»ªè¡¨ï¼‰
        # è¿‡æ»¤æ‰æ— æ•ˆç±»å‹
        valid_df = summary_df[~summary_df['ä»ªè¡¨ç±»å‹'].isin(["æœªçŸ¥", "æœªåˆ†ç±»", "æ— æ³•è¯†åˆ«"])]
        
        if len(valid_df) > 0:
            top_types = valid_df.groupby('ä»ªè¡¨ç±»å‹')['æ•°é‡æ€»å’Œ'].sum().sort_values(ascending=False).head(3)
            
            for instrument_type, total_qty in top_types.items():
                try:
                    logger.info(f"ğŸ”§ æ­£åœ¨ç”Ÿæˆ {instrument_type} å®‰è£…æ¨è...")
                    
                    # è·å–è¯¥ç±»å‹çš„å…¸å‹å‹å·
                    type_data = valid_df[valid_df['ä»ªè¡¨ç±»å‹'] == instrument_type]
                    main_model = type_data.iloc[0]['å‹å·'] if not type_data.empty else ""
                    
                    # ç”Ÿæˆæ¨è
                    recommendation = generator.generate_installation_recommendation(
                        instrument_type=instrument_type,
                        model_spec=main_model,
                        quantity=int(total_qty),
                        process_conditions="",
                        custom_requirements=""
                    )
                    
                    recommendations[instrument_type] = recommendation
                    logger.info(f"âœ… æˆåŠŸç”Ÿæˆ {instrument_type} æ¨è")
                    
                except Exception as e:
                    logger.warning(f"âŒ ç”Ÿæˆ {instrument_type} æ¨èå¤±è´¥: {str(e)}")
                    continue
        else:
            logger.warning("âš ï¸ æ²¡æœ‰æœ‰æ•ˆåˆ†ç±»çš„ä»ªè¡¨ï¼Œæ— æ³•ç”Ÿæˆå…·ä½“æ¨è")
        
        # ç”Ÿæˆæ‰¹é‡å®‰è£…å»ºè®®
        if statistics_info:
            try:
                batch_recommendation = generator.generate_batch_recommendation(statistics_info)
                recommendations['batch_plan'] = batch_recommendation
            except Exception as e:
                logger.warning(f"ç”Ÿæˆæ‰¹é‡å»ºè®®å¤±è´¥: {str(e)}")
        
        return {
            "success": True,
            "recommendations": recommendations,
            "message": f"æˆåŠŸç”Ÿæˆ {len(recommendations)} ä¸ªæ¨èæ–¹æ¡ˆ"
        }
        
    except Exception as e:
        logger.error(f"ç”Ÿæˆå®‰è£…æ¨èå¤±è´¥: {str(e)}")
        return {
            "success": False,
            "recommendations": {},
            "message": f"ç”Ÿæˆå®‰è£…æ¨èå¤±è´¥: {str(e)}"
        }

@tool
def generate_final_report(summary_data: Dict, recommendations: Dict, error_message: str = "") -> Dict[str, Any]:
    """
    ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    
    Args:
        summary_data: æ±‡æ€»æ•°æ®å­—å…¸
        recommendations: æ¨èæ–¹æ¡ˆå­—å…¸
        error_message: é”™è¯¯ä¿¡æ¯
    
    Returns:
        æŠ¥å‘Šç»“æœå­—å…¸ï¼š{"success": bool, "final_report": str, "message": str}
    """
    try:
        from .generate_installation_recommendation import format_recommendation_report
        
        report_parts = []
        
        # æ ‡é¢˜
        report_parts.append("# ä»ªè¡¨è¯†åˆ«ä¸å®‰è£…æ¨èæŠ¥å‘Š\n")
        
        # ç»Ÿè®¡æ±‡æ€»éƒ¨åˆ†
        if summary_data and summary_data.get("data"):
            summary_df = pd.DataFrame(summary_data["data"])
            summary_report = generate_summary_report(summary_df)
            report_parts.append(summary_report)
            report_parts.append("\n" + "="*60 + "\n")
        
        # å®‰è£…æ¨èéƒ¨åˆ†
        if recommendations:
            report_parts.append("# å®‰è£…æ¨èæ–¹æ¡ˆ\n")
            
            # æ‰¹é‡è§„åˆ’
            if 'batch_plan' in recommendations:
                report_parts.append("## é¡¹ç›®æ•´ä½“è§„åˆ’")
                report_parts.append(recommendations['batch_plan'])
                report_parts.append("\n" + "-"*40 + "\n")
            
            # åˆ†ç±»å‹æ¨è
            for instrument_type, recommendation in recommendations.items():
                if instrument_type != 'batch_plan':
                    report_parts.append(f"## {instrument_type}ä¸“é¡¹æ¨è")
                    if isinstance(recommendation, dict):
                        formatted_report = format_recommendation_report(recommendation)
                        report_parts.append(formatted_report)
                    else:
                        report_parts.append(str(recommendation))
                    report_parts.append("\n" + "-"*40 + "\n")
        
        # é”™è¯¯ä¿¡æ¯
        if error_message:
            report_parts.append(f"\nâš ï¸ å¤„ç†è¿‡ç¨‹ä¸­çš„é—®é¢˜ï¼š{error_message}")
        
        final_report = "\n".join(report_parts)
        
        return {
            "success": True,
            "final_report": final_report,
            "message": "æœ€ç»ˆæŠ¥å‘Šç”Ÿæˆå®Œæˆ"
        }
        
    except Exception as e:
        logger.error(f"ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šå¤±è´¥: {str(e)}")
        return {
            "success": False,
            "final_report": f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}",
            "message": f"ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šå¤±è´¥: {str(e)}"
        }

# å·¥å…·åˆ—è¡¨ï¼Œç”¨äºLangGraphæ³¨å†Œ
INSTRUMENT_TOOLS = [
    extract_excel_tables,
    parse_instrument_table,
    classify_instrument_types,
    summarize_instrument_statistics,
    match_installation_standards,
    generate_installation_recommendations,
    generate_final_report
] 