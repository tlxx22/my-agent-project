"""
å¢å¼ºRAGæ£€ç´¢å™¨
é€šè¿‡æŸ¥è¯¢æ‰©å±•ã€é‡æ’åºã€é¢†åŸŸé€‚åº”ç­‰æŠ€æœ¯æå‡æ£€ç´¢è´¨é‡å’Œæ³›åŒ–æ€§
"""
import os
import re
import pickle
from typing import List, Dict, Tuple, Optional, Set
import logging
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from tools.build_index import DocumentIndexer
from tools.match_standard_clause import StandardClauseRetriever

logger = logging.getLogger(__name__)

class EnhancedRAGRetriever:
    """å¢å¼ºçš„RAGæ£€ç´¢å™¨"""
    
    def __init__(self, index_path: str = None):
        """åˆå§‹åŒ–å¢å¼ºæ£€ç´¢å™¨"""
        self.base_retriever = StandardClauseRetriever(index_path)
        self.instrument_vocabulary = self._build_instrument_vocabulary()
        self.semantic_enhancer = self._build_semantic_enhancer()
        
    def _build_instrument_vocabulary(self) -> Dict[str, Dict]:
        """æ„å»ºä»ªè¡¨é¢†åŸŸè¯æ±‡è¡¨å’Œè¯­ä¹‰å…³ç³»ï¼ˆä½¿ç”¨åŸºæœ¬ç¡¬ç¼–ç è¯æ±‡è¡¨ï¼‰"""
        logger.info("æ„å»ºåŸºæœ¬ä»ªè¡¨è¯æ±‡è¡¨...")
        return self._build_basic_vocabulary()
    
    def _build_basic_vocabulary(self) -> Dict[str, Dict]:
        """åŸºæœ¬è¯æ±‡è¡¨ï¼ˆç¡¬ç¼–ç ï¼‰â€”â€”è¦†ç›–å¸¸è§æµ‹æ§/åˆ†æ/æ‰§è¡Œä»ªè¡¨"""
        return {
            # 1 â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ¸©åº¦
            "æ¸©åº¦ä»ªè¡¨": {
                "main_types": [
                    "çƒ­ç”µå¶", "çƒ­ç”µé˜»", "åŒé‡‘å±æ¸©åº¦è®¡", "å‹åŠ›å¼æ¸©åº¦è®¡",
                    "è¡¨é¢æ¸©åº¦è®¡", "æ¸©åº¦å˜é€å™¨", "å…‰çº¤æ¸©åº¦è®¡"
                ],
                "related_terms": [
                    "æµ‹æ¸©", "æ„Ÿæ¸©", "æ¸©åº¦ä¼ æ„Ÿå™¨", "ä¿æŠ¤ç®¡", "æµ‹æ¸©ç‚¹",
                    "PT100", "PT1000", "Kå‹", "Jå‹", "Tå‹", "Eå‹",
                    "è¡¥å¿å¯¼çº¿", "æ¥çº¿ç›’", "æ¸©åŒ…", "æ¯›ç»†ç®¡", "æŠ—éœ‡"
                ],
                "installation_terms": [
                    "å®‰è£…ä½ç½®", "å®‰è£…æ·±åº¦", "æ’å…¥é•¿åº¦", "å€¾æ–œå®‰è£…",
                    "å›ºå®šæ–¹å¼", "ä¼´çƒ­", "éš”çƒ­", "å¼¯æ›²åŠå¾„", "é˜²å¼¯æ›²",
                    "é˜²ç£¨æŸ", "é˜²å†²åˆ·"
                ],
                "materials": [
                    "ä¸é”ˆé’¢", "316L", "304", "å“ˆæ°åˆé‡‘", "é™¶ç“·", "é‡‘å±å¥—ç®¡"
                ]
            },

            # 2 â”€â”€â”€â”€â”€â”€â”€â”€â”€ å‹åŠ›
            "å‹åŠ›ä»ªè¡¨": {
                "main_types": [
                    "å‹åŠ›å˜é€å™¨", "å·®å‹å˜é€å™¨", "å‹åŠ›è¡¨", "ç»å‹è¡¨",
                    "å¾®å‹è¡¨", "å‹åŠ›å¼€å…³", "éš”è†œå‹åŠ›è¡¨"
                ],
                "related_terms": [
                    "å‹åŠ›æµ‹é‡", "å–å‹", "å‹åŠ›ä¼ æ„Ÿ", "å–å‹ç‚¹", "å¯¼å‹ç®¡",
                    "è†œç‰‡", "å¼¹ç°§ç®¡", "ä¸‰é˜€ç»„", "éš”ç¦»è†œç‰‡", "æ¯›ç»†ç®¡",
                    "æ­£å‹å®¤", "è´Ÿå‹å®¤", "ç¼“å†²å™¨"
                ],
                "installation_terms": [
                    "å–å‹å£", "å®‰è£…é«˜åº¦", "å¯¼å‹ç®¡è·¯", "ç¯å½¢å†·å‡å¼¯",
                    "Uå‹å†·å‡å¼¯", "å†·å‡å™¨", "è„‰å†²ç®¡å¡åº¦", "æ’æ±¡é˜€",
                    "å¹æ‰«", "é˜²å µ", "ä¼´çƒ­"
                ],
                "materials": [
                    "ä¸é”ˆé’¢ç®¡", "é“œç®¡", "èšå››æ°Ÿä¹™çƒ¯", "å“ˆæ°åˆé‡‘", "è†œç‰‡ææ–™"
                ]
            },

            # 3 â”€â”€â”€â”€â”€â”€â”€â”€â”€ æµé‡
            "æµé‡ä»ªè¡¨": {
                "main_types": [
                    "å­”æ¿æµé‡è®¡", "å–·å’€æµé‡è®¡", "æ–‡ä¸˜é‡Œæµé‡è®¡",
                    "ç”µç£æµé‡è®¡", "æ¶¡è¡—æµé‡è®¡", "æ¶¡è½®æµé‡è®¡",
                    "è½¬å­æµé‡è®¡", "é¶å¼æµé‡è®¡", "ç§‘é‡Œå¥¥åˆ©è´¨é‡æµé‡è®¡",
                    "è¶…å£°æ³¢æµé‡è®¡", "æ¤­åœ†é½¿è½®æµé‡è®¡", "çš®æ‰˜ç®¡", "å‡é€Ÿç®¡"
                ],
                "related_terms": [
                    "æµé‡æµ‹é‡", "æµé€Ÿ", "æµä½“", "ä»‹è´¨æµåŠ¨", "ç›´ç®¡æ®µ",
                    "ä¸Šæ¸¸", "ä¸‹æ¸¸", "å®šå‹å­”", "å‡å‹ç¯", "å–å‹å­”",
                    "æ»¡ç®¡", "æ¥åœ°ç¯", "Î²ç³»æ•°", "ç”µæ", "è¡¬é‡Œ", "ä¿¡å·æ”¾å¤§å™¨"
                ],
                "installation_terms": [
                    "ä¸Šæ¸¸ç›´ç®¡æ®µ", "ä¸‹æ¸¸ç›´ç®¡æ®µ", "ç®¡é“ä¸­å¿ƒ", "æµå‘",
                    "æ¥åœ°", "æ³•å…°è¿æ¥", "åŒè½´åº¦", "æ•´æµå™¨", "æ”¯æ¶", "å‡æŒ¯"
                ],
                "materials": [
                    "è¡¬é‡Œææ–™", "ç”µæææ–™", "å“ˆæ°åˆé‡‘", "316L", "æ³•å…°",
                    "å¯†å°å«ç‰‡", "æ¥åœ°çº¿"
                ]
            },

            # 4 â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ¶²ä½ / ç‰©ä½
            "æ¶²ä½ä»ªè¡¨": {
                "main_types": [
                    "æµ®çƒæ¶²ä½è®¡", "æµ®ç­’æ¶²ä½è®¡", "ç£ç¿»æ¿æ¶²ä½è®¡", "å¯¼æ³¢é›·è¾¾æ¶²ä½è®¡",
                    "é›·è¾¾æ¶²ä½è®¡", "è¶…å£°æ³¢æ¶²ä½è®¡", "å·®å‹å¼æ¶²ä½è®¡", "å°„çº¿æ¶²ä½è®¡"
                ],
                "related_terms": [
                    "æ¶²ä½æµ‹é‡", "ç‰©ä½", "ç•Œé¢", "æ¶²ä½èŒƒå›´", "æµ®å­",
                    "æµ®çƒ", "å¯¼æ³¢æ†", "è¡¥å¿å¼å¹³è¡¡å®¹å™¨", "æ—è·¯è…”ä½“",
                    "å®‰è£…ç›²åŒº", "å›æ³¢", "æ³¢æŸè§’"
                ],
                "installation_terms": [
                    "å®‰è£…ä½ç½®", "å®‰è£…é«˜åº¦", "å¯¼å‘ç®¡", "æ—è·¯ç®¡",
                    "å–æºç®¡", "ç›²åŒº", "é˜²æ³¢æŒ¡æ¿", "è¡¥å¿å®¹å™¨", "é˜²æŒ‚æ–™"
                ],
                "materials": [
                    "304", "316L", "å“ˆæ°åˆé‡‘", "å¯¼æ³¢æ†", "ç¼†ç»³", "æ³•å…°"
                ]
            },

            # 5 â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ¹¿åº¦
            "æ¹¿åº¦ä»ªè¡¨": {
                "main_types": ["æ¸©æ¹¿åº¦å˜é€å™¨", "æ¹¿åº¦ä¼ æ„Ÿå™¨", "éœ²ç‚¹æ¸©æ¹¿åº¦è®°å½•ä»ª"],
                "related_terms": [
                    "æ¹¿åº¦", "ç›¸å¯¹æ¹¿åº¦", "æ¹¿æ•å…ƒä»¶", "å¹²æ¹¿çƒ",
                    "é€æ°”è†œ", "å†·å‡", "ç©ºæ°”å¯¹æµ"
                ],
                "installation_terms": [
                    "é€šé£", "é®é˜³", "é˜²å†·å‡", "å®‰è£…é«˜åº¦", "è¿‡æ»¤å¸½"
                ],
                "materials": ["èšå››æ°Ÿä¹™çƒ¯æ»¤è†œ", "ä¸é”ˆé’¢ç½‘ç½©"]
            },

            # 6 â”€â”€â”€â”€â”€â”€â”€â”€â”€ éœ²ç‚¹
            "éœ²ç‚¹ä»ªè¡¨": {
                "main_types": ["éœ²ç‚¹ä»ª", "éœ²ç‚¹å˜é€å™¨"],
                "related_terms": [
                    "éœ²ç‚¹", "å¾®é‡æ°´åˆ†", "é™¶ç“·ä¼ æ„ŸèŠ¯ç‰‡", "æµ‹é‡è…”", "å¹²ç‡¥å‰‚"
                ],
                "installation_terms": [
                    "æ—è·¯å–æ ·", "å¸¸æ¸©å–æ ·", "ä¿æ¸©", "é®å…‰", "é˜²å†·å‡"
                ],
                "materials": ["316L", "é“åˆé‡‘", "å¯†å°åœˆ"]
            },

            # 7 â”€â”€â”€â”€â”€â”€â”€â”€â”€ å¯†åº¦ / é‡é‡
            "å¯†åº¦ä»ªè¡¨": {
                "main_types": [
                    "æŒ¯ç­’å¯†åº¦è®¡", "ç§‘é‡Œå¥¥åˆ©å¯†åº¦è®¡", "åœ¨çº¿å¯†åº¦å˜é€å™¨",
                    "ç§°é‡ä¼ æ„Ÿå™¨", "è´Ÿè·ä¼ æ„Ÿå™¨"
                ],
                "related_terms": [
                    "å¯†åº¦æµ‹é‡", "è´¨é‡", "æŒ¯ç­’", "å¯†åº¦è®¡", "ç§°é‡",
                    "å‰ªåˆ‡æ¢", "å‹å¼", "ç¼“å†²å—"
                ],
                "installation_terms": [
                    "å‚ç›´å—åŠ›", "å‡æŒ¯æ”¯æ¶", "é›¶ç‚¹æ ‡å®š", "æ”¯æ’‘å¹³å°"
                ],
                "materials": ["ä¸é”ˆé’¢", "åˆé‡‘é’¢", "æ©¡èƒ¶å‡æŒ¯å«"]
            },

            # 8 â”€â”€â”€â”€â”€â”€â”€â”€â”€ æŒ¯åŠ¨
            "æŒ¯åŠ¨ä»ªè¡¨": {
                "main_types": ["åŠ é€Ÿåº¦è®¡", "é€Ÿåº¦ä¼ æ„Ÿå™¨", "æŒ¯åŠ¨ç›‘æµ‹ä»ª"],
                "related_terms": [
                    "æŒ¯åŠ¨", "åŠ é€Ÿåº¦", "ä½ç§»", "ä¸»çµæ•è½´",
                    "ä¸‰è½´åº§", "é¢‘å“", "å†²å‡»"
                ],
                "installation_terms": [
                    "å›ºç´§èºé’‰", "ç²˜è´´", "ç£å¸", "å‡æŒ¯", "æ¸©åº¦è¡¥å¿"
                ],
                "materials": ["é’›åˆé‡‘å£³ä½“", "é™¶ç“·å‰ªåˆ‡ç‰‡"]
            },

            # 9 â”€â”€â”€â”€â”€â”€â”€â”€â”€ è½¬é€Ÿ / é€Ÿåº¦
            "è½¬é€Ÿä»ªè¡¨": {
                "main_types": ["è½¬é€Ÿæ¢å¤´", "æµ‹é€Ÿé½¿è½®", "éœå°”ä¼ æ„Ÿå™¨", "ç£ç”µé€Ÿåº¦è®¡"],
                "related_terms": [
                    "è½¬é€Ÿ", "é€Ÿåº¦", "è„‰å†²", "éœå°”å¼€å…³", "ç£ç”µæ„Ÿåº”"
                ],
                "installation_terms": ["é—´éš™", "åŒå¿ƒåº¦", "æ”¯æ¶", "å±è”½"],
                "materials": ["ä¸é”ˆé’¢ç½©", "æ°¸ç£ä½“", "å±è”½çº¿"]
            },

            # 10 â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ°”ä½“æ£€æµ‹
            "æ°”ä½“æ£€æµ‹ä»ªè¡¨": {
                "main_types": [
                    "å¯ç‡ƒæ°”ä½“æ¢æµ‹å™¨", "æ¯’æ€§æ°”ä½“æ¢æµ‹å™¨", "æ°§å«é‡åˆ†æä»ª",
                    "çº¢å¤–æ°”ä½“åˆ†æä»ª"
                ],
                "related_terms": [
                    "æ°”ä½“æ£€æµ‹", "æ¢å¤´", "æ‰©æ•£å¼", "æ³µå¸å¼",
                    "æ ‡å®šç½©", "æŠ¥è­¦", "å®‰è£…é«˜åº¦"
                ],
                "installation_terms": [
                    "æµé‡æ§åˆ¶", "é®é›¨ç½©", "é˜²å°˜", "é˜²çˆ†", "ç‹¬ç«‹æ¥åœ°"
                ],
                "materials": ["é“åˆé‡‘å£³ä½“", "ä¸é”ˆé’¢é˜²çˆ†è…”", "è¿‡æ»¤ç‰‡"]
            },

            # 11 â”€â”€â”€â”€â”€â”€â”€â”€â”€ åˆ†æ / æˆåˆ†
            "åˆ†æä»ªè¡¨": {
                "main_types": [
                    "æ°”ç›¸è‰²è°±", "åœ¨çº¿çº¢å¤–åˆ†æä»ª", "pH è®¡",
                    "ç”µå¯¼ç‡ä»ª", "æº¶æ°§ä»ª", "æµŠåº¦è®¡"
                ],
                "related_terms": [
                    "å–æ ·", "é¢„å¤„ç†", "ä»£è¡¨æ€§æ ·å“", "è¿‡æ»¤å™¨",
                    "æ’æ”¾ç®¡", "æ ·å“å†·å´å™¨", "æ ‡å®š", "äº¤å‰æ•æ„Ÿ"
                ],
                "installation_terms": [
                    "å–æ ·æ¢å¤´", "ä¼´çƒ­ç®¡çº¿", "æ—è·¯å–æ ·",
                    "æ’æ¸©", "å†·å‡", "æ’æ¶²"
                ],
                "materials": ["PFA ç®¡", "316L", "ç»ç’ƒç”µæ", "éš”è†œ"]
            },

            # 12 â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ§åˆ¶è®¾å¤‡
            "æ§åˆ¶è®¾å¤‡": {
                "main_types": [
                    "è°ƒèŠ‚é˜€", "è‡ªåŠ›å¼è°ƒèŠ‚é˜€", "ç”µåŠ¨æ‰§è¡Œæœºæ„",
                    "æ°”åŠ¨æ‰§è¡Œæœºæ„", "æ¶²åŠ¨æ‰§è¡Œæœºæ„", "é˜€é—¨å®šä½å™¨",
                    "ç”µç£é˜€"
                ],
                "related_terms": [
                    "æ§åˆ¶", "è°ƒèŠ‚", "æ‰§è¡Œ", "å®šä½å™¨",
                    "è¡Œç¨‹", "è½¬çŸ©", "å¼€åº¦", "ä¿¡å·", "è”é”"
                ],
                "installation_terms": [
                    "å®‰è£…æ–¹å‘", "ä»‹è´¨æµå‘", "è¿æ¥æ–¹å¼",
                    "è¡Œç¨‹è°ƒæ•´", "ä¿¡å·æ¥çº¿", "è¿æ†", "æ”¯æ¶", "å‡æŒ¯"
                ],
                "materials": [
                    "é˜€ä½“ææ–™", "316L", "WC6", "å¯†å°ä»¶", "å¼¹ç°§", "æ‰§è¡Œæœºæ„"
                ]
            },

            # 13 â”€â”€â”€â”€â”€â”€â”€â”€â”€ é€šç”¨
            "é€šç”¨ä»ªè¡¨": {
                "main_types": ["ä»ªè¡¨", "ä¼ æ„Ÿå™¨", "å˜é€å™¨", "è®¡é‡å™¨", "æ˜¾ç¤ºå™¨"],
                "related_terms": [
                    "æµ‹é‡", "æ£€æµ‹", "ç›‘æµ‹", "ä¼ æ„Ÿ", "ä¿¡å·",
                    "æ˜¾ç¤º", "æŠ¥è­¦", "è¾“å‡º", "è”é”"
                ],
                "installation_terms": [
                    "å®‰è£…ä½ç½®", "å®‰è£…è¦æ±‚", "å›ºå®šæ–¹å¼",
                    "è¿æ¥", "å±è”½", "æ¥çº¿", "æ¥åœ°", "é˜²çˆ†"
                ],
                "materials": [
                    "ä¸é”ˆé’¢", "é“åˆé‡‘", "å·¥ç¨‹å¡‘æ–™", "é˜²æŠ¤ç­‰çº§ IP65",
                    "IP67", "IP68"
                ]
            }
        }
    
    def _build_semantic_enhancer(self) -> Dict[str, List[str]]:
        """æ„å»ºè¯­ä¹‰å¢å¼ºæ˜ å°„"""
        return {
            "å®‰è£…": ["å®‰è£…", "å®‰è£…è¦æ±‚", "å®‰è£…æ–¹æ³•", "å®‰è£…ä½ç½®", "å®‰è£…é«˜åº¦", "å®‰è£…æ–¹å‘", "å›ºå®š", "æ”¯æ’‘"],
            "ææ–™": ["ææ–™", "æè´¨", "é€‰æ", "ææ–™è¦æ±‚", "ç®¡è·¯ææ–™", "é˜€é—¨ææ–™", "ç”µç¼†"],
            "è¿æ¥": ["è¿æ¥", "æ¥çº¿", "é…ç®¡", "é…çº¿", "æ¥å¤´", "æ³•å…°", "èºçº¹"],
            "ä¿æŠ¤": ["ä¿æŠ¤", "é˜²æŠ¤", "ä¿æŠ¤ç®¡", "ä¿æŠ¤å¥—", "é˜²è…", "é˜²çˆ†", "å¯†å°"],
            "ç»´æŠ¤": ["ç»´æŠ¤", "ä¿å…»", "æ£€ä¿®", "æ ¡å‡†", "æ¸…æ´—", "æ›´æ¢"],
            "å®‰å…¨": ["å®‰å…¨", "å®‰å…¨è¦æ±‚", "æ³¨æ„äº‹é¡¹", "é˜²æŠ¤æªæ–½", "æ¥åœ°", "ç»ç¼˜"]
        }

    def enhance_query(self, query: str, instrument_type: str = None) -> List[str]:
        """æŸ¥è¯¢å¢å¼ºï¼šåŸºäºé¢†åŸŸçŸ¥è¯†æ‰©å±•æŸ¥è¯¢"""
        enhanced_queries = [query]  # ä¿ç•™åŸå§‹æŸ¥è¯¢
        
        # 1. è‡ªåŠ¨è¯†åˆ«ä»ªè¡¨ç±»å‹ï¼ˆå¦‚æœæœªæä¾›ï¼‰
        if not instrument_type:
            instrument_type = self._identify_instrument_type(query)
        
        # 2. åŸºäºä»ªè¡¨ç±»å‹æ·»åŠ ç›¸å…³è¯æ±‡
        if instrument_type:
            vocab = self._get_instrument_vocabulary(instrument_type)
            if vocab:
                for main_type in vocab.get("main_types", []):
                    if main_type.lower() in query.lower():
                        for term in vocab.get("related_terms", [])[:3]:
                            enhanced_queries.append(f"{main_type} {term}")
                
                if any(keyword in query.lower() for keyword in ["å®‰è£…", "å®‰è£…è¦æ±‚", "å®‰è£…æ–¹æ³•"]):
                    for install_term in vocab.get("installation_terms", [])[:2]:
                        enhanced_queries.append(f"{instrument_type} {install_term}")
        
        # 3. åŸºäºæŸ¥è¯¢æ„å›¾æ·»åŠ è¯­ä¹‰æ‰©å±•
        for semantic_key, expansions in self.semantic_enhancer.items():
            if semantic_key in query:
                for expansion in expansions[:2]:
                    if expansion != semantic_key:
                        enhanced_query = query.replace(semantic_key, expansion)
                        enhanced_queries.append(enhanced_query)
        
        # 4. å»é‡å¹¶é™åˆ¶æŸ¥è¯¢æ•°é‡
        unique_queries = []
        seen = set()
        for q in enhanced_queries:
            if q.lower() not in seen:
                unique_queries.append(q)
                seen.add(q.lower())
        
        return unique_queries[:5]  # æœ€å¤šè¿”å›5ä¸ªæŸ¥è¯¢

    def _identify_instrument_type(self, query: str) -> Optional[str]:
        """åŸºäºæŸ¥è¯¢å†…å®¹è‡ªåŠ¨è¯†åˆ«ä»ªè¡¨ç±»å‹"""
        query_lower = query.lower()
        
        for category, vocab in self.instrument_vocabulary.items():
            for main_type in vocab.get("main_types", []):
                if main_type.lower() in query_lower:
                    return main_type
            
            for related_term in vocab.get("related_terms", []):
                if related_term.lower() in query_lower:
                    return vocab["main_types"][0] if vocab["main_types"] else None
        
        return None
    
    def _get_instrument_vocabulary(self, instrument_type: str) -> Optional[Dict]:
        """è·å–ç‰¹å®šä»ªè¡¨ç±»å‹çš„è¯æ±‡ä¿¡æ¯"""
        for category, vocab in self.instrument_vocabulary.items():
            if instrument_type in vocab.get("main_types", []):
                return vocab
        return None

    def advanced_search(self, query: str, instrument_type: str = None, top_k: int = 5) -> List[Dict]:
        """
        å¢å¼ºæœç´¢ï¼šç»“åˆæŸ¥è¯¢æ‰©å±•å’Œé‡æ’åº
        
        Args:
            query: æŸ¥è¯¢å­—ç¬¦ä¸²
            instrument_type: ä»ªè¡¨ç±»å‹
            top_k: è¿”å›ç»“æœæ•°é‡
        
        Returns:
            é‡æ’åºåçš„æœç´¢ç»“æœ
        """
        # 1. æŸ¥è¯¢å¢å¼º
        enhanced_queries = self.enhance_query(query, instrument_type)
        
        # 2. å¤šæŸ¥è¯¢æ£€ç´¢
        all_results = []
        seen_content = set()
        
        for i, enhanced_query in enumerate(enhanced_queries):
            # ä¸ºä¸åŒæŸ¥è¯¢è®¾ç½®ä¸åŒçš„æƒé‡
            weight = 1.0 - (i * 0.1)  # åŸå§‹æŸ¥è¯¢æƒé‡æœ€é«˜
            
            results = self.base_retriever.search_related_clauses(
                enhanced_query, 
                top_k=top_k * 3,  # ğŸ¯ ä»2å€å¢åŠ åˆ°3å€ï¼Œè·å–æ›´å¤šå€™é€‰ç»“æœä¾›é‡æ’åº
                min_similarity=0.6  # é™ä½åˆå§‹é˜ˆå€¼ï¼Œåç»­é‡æ’åº
            )
            
            for result in results:
                content = result['content']
                if content not in seen_content:
                    seen_content.add(content)
                    # æ·»åŠ æŸ¥è¯¢æƒé‡å’Œæ¥æºä¿¡æ¯
                    result['query_weight'] = weight
                    result['source_query'] = enhanced_query
                    all_results.append(result)
        
        # 3. é‡æ’åº
        reranked_results = self._rerank_results(all_results, query, instrument_type)
        
        return reranked_results[:top_k]
    
    def _rerank_results(self, results: List[Dict], original_query: str, instrument_type: str = None) -> List[Dict]:
        """ç»“æœé‡æ’åºï¼šåŸºäºå¤šä¸ªå› ç´ é‡æ–°è®¡ç®—ç›¸å…³æ€§åˆ†æ•°"""
        for result in results:
            content = result['content']
            original_score = result['score']
            query_weight = result.get('query_weight', 1.0)
            
            # é‡æ–°è®¡ç®—ç»¼åˆåˆ†æ•°
            rerank_score = self._calculate_rerank_score(
                content, original_query, instrument_type, original_score, query_weight
            )
            
            result['rerank_score'] = rerank_score
            result['original_score'] = original_score
        
        # æŒ‰é‡æ’åºåˆ†æ•°æ’åº
        results.sort(key=lambda x: x['rerank_score'], reverse=True)
        
        return results
    
    def _calculate_rerank_score(self, content: str, query: str, instrument_type: str, 
                               original_score: float, query_weight: float) -> float:
        """
        è®¡ç®—é‡æ’åºåˆ†æ•°
        
        ç»¼åˆè€ƒè™‘ï¼š
        1. åŸå§‹å‘é‡ç›¸ä¼¼åº¦
        2. æŸ¥è¯¢æƒé‡
        3. ä»ªè¡¨ç±»å‹åŒ¹é…åº¦
        4. å…³é”®è¯åŒ¹é…åº¦
        5. å†…å®¹è´¨é‡è¯„åˆ†
        """
        content_lower = content.lower()
        query_lower = query.lower()
        
        # 1. åŸºç¡€åˆ†æ•°ï¼ˆåŸå§‹ç›¸ä¼¼åº¦ * æŸ¥è¯¢æƒé‡ï¼‰
        base_score = original_score * query_weight
        
        # 2. ä»ªè¡¨ç±»å‹åŒ¹é…åŠ åˆ†
        type_bonus = 0.0
        if instrument_type:
            vocab = self._get_instrument_vocabulary(instrument_type)
            if vocab:
                # ç²¾ç¡®åŒ¹é…ä¸»è¦ç±»å‹
                if instrument_type.lower() in content_lower:
                    type_bonus += 0.2
                
                # åŒ¹é…ç›¸å…³æœ¯è¯­
                related_matches = sum(1 for term in vocab.get("related_terms", []) 
                                    if term.lower() in content_lower)
                type_bonus += min(related_matches * 0.05, 0.15)
        
        # 3. æŸ¥è¯¢å…³é”®è¯åŒ¹é…åŠ åˆ†
        query_words = set(query_lower.split())
        content_words = set(content_lower.split())
        keyword_overlap = len(query_words.intersection(content_words)) / len(query_words) if query_words else 0
        keyword_bonus = keyword_overlap * 0.15
        
        # 4. å†…å®¹è´¨é‡è¯„åˆ†
        quality_score = self._assess_content_quality(content, query)
        
        # 5. åå‘æƒ©ç½šï¼šé™ä½æ— å…³å†…å®¹åˆ†æ•°
        penalty = self._calculate_irrelevance_penalty(content, query, instrument_type)
        
        # ç»¼åˆåˆ†æ•°è®¡ç®—
        final_score = base_score + type_bonus + keyword_bonus + quality_score - penalty
        
        return max(0.0, min(1.0, final_score))  # é™åˆ¶åœ¨[0,1]èŒƒå›´å†…
    
    def _assess_content_quality(self, content: str, query: str) -> float:
        """è¯„ä¼°å†…å®¹è´¨é‡"""
        quality_score = 0.0
        
        # é•¿åº¦é€‚ä¸­æ€§ï¼ˆå¤ªçŸ­æˆ–å¤ªé•¿éƒ½å‡åˆ†ï¼‰
        length = len(content)
        if 50 <= length <= 300:
            quality_score += 0.05
        elif length < 20:
            quality_score -= 0.1
        
        # ç»“æ„åŒ–ç¨‹åº¦ï¼ˆåŒ…å«æ¡æ¬¾å·ã€ç¼–å·ç­‰ï¼‰
        if re.search(r'ç¬¬\s*\d+\.\d+\.\d+\s*æ¡', content):
            quality_score += 0.1
        elif re.search(r'\d+[ã€ï¼]\s*', content):
            quality_score += 0.05
        
        # æŠ€æœ¯æœ¯è¯­å¯†åº¦
        technical_terms = ["å®‰è£…", "è¦æ±‚", "è§„å®š", "åº”", "å®œ", "ä¸åº”", "å¿…é¡»", "ç¦æ­¢"]
        term_count = sum(1 for term in technical_terms if term in content)
        quality_score += min(term_count * 0.02, 0.1)
        
        return quality_score
    
    def _calculate_irrelevance_penalty(self, content: str, query: str, instrument_type: str) -> float:
        """è®¡ç®—æ— å…³å†…å®¹çš„æƒ©ç½šåˆ†æ•°"""
        penalty = 0.0
        content_lower = content.lower()
        
        # å¦‚æœæŒ‡å®šäº†ä»ªè¡¨ç±»å‹ï¼Œæ£€æŸ¥æ˜¯å¦åŒ…å«å…¶ä»–ä¸ç›¸å…³çš„ä»ªè¡¨ç±»å‹
        if instrument_type:
            other_instruments = []
            for category, vocab in self.instrument_vocabulary.items():
                for main_type in vocab.get("main_types", []):
                    if main_type != instrument_type:
                        other_instruments.append(main_type.lower())
            
            # å¦‚æœå†…å®¹å¼ºçƒˆæŒ‡å‘å…¶ä»–ä»ªè¡¨ç±»å‹ï¼Œå¢åŠ æƒ©ç½š
            other_type_mentions = sum(1 for other_type in other_instruments 
                                    if other_type in content_lower)
            if other_type_mentions >= 2:
                penalty += 0.3
            elif other_type_mentions == 1:
                penalty += 0.1
        
        # è¿‡äºé€šç”¨çš„å†…å®¹æƒ©ç½š
        generic_patterns = [
            r'^[^ã€‚]{0,30}$',  # è¿‡çŸ­ä¸”æ²¡æœ‰å¥å·
            r'ä¸€èˆ¬è§„å®š',
            r'æ€»åˆ™',
            r'åŸºæœ¬è¦æ±‚'
        ]
        
        for pattern in generic_patterns:
            if re.search(pattern, content_lower):
                penalty += 0.1
                break
        
        return penalty

    def intelligent_instrument_search(self, instrument_info: Dict) -> List[Dict]:
        """
        æ™ºèƒ½ä»ªè¡¨æœç´¢ï¼šåŸºäºè¡¨æ ¼ä¸­çš„ä»ªè¡¨ä¿¡æ¯è¿›è¡Œæ™ºèƒ½æœç´¢
        å¯¹ä¸åŒä»ªè¡¨ç±»å‹å…·æœ‰è‰¯å¥½çš„æ³›åŒ–æ€§
        
        Args:
            instrument_info: ä»ªè¡¨ä¿¡æ¯å­—å…¸ï¼ŒåŒ…å«ç±»å‹ã€æµ‹é‡èŒƒå›´ã€å·¥è‰ºæ¡ä»¶ç­‰
        
        Returns:
            ç›¸å…³çš„å®‰è£…è§„èŒƒåˆ—è¡¨
        """
        instrument_type = instrument_info.get('ä»ªè¡¨ç±»å‹', instrument_info.get('type', ''))
        measure_range = instrument_info.get('æµ‹é‡èŒƒå›´', instrument_info.get('range', ''))
        process_condition = instrument_info.get('å·¥è‰ºæ¡ä»¶', instrument_info.get('condition', ''))
        
        # æ„å»ºæ™ºèƒ½æŸ¥è¯¢
        search_queries = []
        
        # 1. åŸºç¡€æŸ¥è¯¢
        if instrument_type:
            search_queries.append(f"{instrument_type}å®‰è£…")
            search_queries.append(f"{instrument_type}å®‰è£…è¦æ±‚")
        
        # 2. åŸºäºæµ‹é‡èŒƒå›´çš„æŸ¥è¯¢
        if measure_range:
            # æå–æ¸©åº¦ã€å‹åŠ›ç­‰å…³é”®ä¿¡æ¯
            if 'â„ƒ' in measure_range or 'Â°C' in measure_range:
                if 'é«˜æ¸©' in measure_range or any(temp in measure_range for temp in ['400', '500', '600']):
                    search_queries.append(f"{instrument_type}é«˜æ¸©å®‰è£…")
                if 'ä½æ¸©' in measure_range or '-' in measure_range:
                    search_queries.append(f"{instrument_type}ä½æ¸©å®‰è£…")
            
            if 'MPa' in measure_range or 'kPa' in measure_range:
                if any(pressure in measure_range for pressure in ['é«˜å‹', '10', '20', '50']):
                    search_queries.append(f"{instrument_type}é«˜å‹å®‰è£…")
        
        # 3. åŸºäºå·¥è‰ºæ¡ä»¶çš„æŸ¥è¯¢
        if process_condition:
            if 'è…èš€' in process_condition:
                search_queries.append(f"{instrument_type}é˜²è…ææ–™")
            if 'é«˜æ¸©' in process_condition:
                search_queries.append(f"{instrument_type}é«˜æ¸©ä¿æŠ¤")
            if 'æŒ¯åŠ¨' in process_condition:
                search_queries.append(f"{instrument_type}é˜²æŒ¯å®‰è£…")
        
        # 4. æ‰§è¡Œæœç´¢å¹¶åˆå¹¶ç»“æœ
        all_results = []
        seen_content = set()
        
        for query in search_queries:
            results = self.advanced_search(query, instrument_type, top_k=3)
            for result in results:
                if result['content'] not in seen_content:
                    seen_content.add(result['content'])
                    result['search_query'] = query
                    all_results.append(result)
        
        # æŒ‰é‡æ’åºåˆ†æ•°æ’åº
        all_results.sort(key=lambda x: x.get('rerank_score', x.get('score', 0)), reverse=True)
        
        return all_results[:5]  # è¿”å›å‰5ä¸ªæœ€ç›¸å…³çš„ç»“æœ
    
    def get_comprehensive_standards(self, instrument_type: str) -> Dict[str, List[Dict]]:
        """
        è·å–æŸä»ªè¡¨ç±»å‹çš„ç»¼åˆå®‰è£…è§„èŒƒä¿¡æ¯ï¼ˆå…¼å®¹æ¥å£ï¼‰
        
        Args:
            instrument_type: ä»ªè¡¨ç±»å‹
        
        Returns:
            åŒ…å«å®‰è£…æ–¹æ³•ã€ææ–™è¦æ±‚ç­‰åˆ†ç±»ä¿¡æ¯çš„å­—å…¸
        """
        result = {
            'instrument_type': instrument_type,
            'installation_methods': [],
            'material_requirements': [],
            'safety_requirements': [],
            'maintenance_requirements': []
        }
        
        try:
            # æœç´¢å®‰è£…æ–¹æ³• - ğŸ¯ å¢åŠ åˆ°5æ¡ï¼Œä¾›LLMç­›é€‰
            installation_results = self.advanced_search(f"{instrument_type}å®‰è£…è¦æ±‚", instrument_type, top_k=5)
            for res in installation_results:
                # è½¬æ¢ä¸ºåŸºç¡€æ£€ç´¢å™¨å…¼å®¹çš„æ ¼å¼
                result['installation_methods'].append({
                    'content': res['content'],
                    'score': res.get('rerank_score', res.get('score', 0)),
                    'query': f"{instrument_type}å®‰è£…è¦æ±‚"
                })
            
            # æœç´¢ææ–™è¦æ±‚ - ğŸ¯ å¢åŠ åˆ°3æ¡ï¼Œä¾›LLMç­›é€‰
            material_results = self.advanced_search(f"{instrument_type}ææ–™è¦æ±‚", instrument_type, top_k=3)
            for res in material_results:
                if any(keyword in res['content'] for keyword in ['ææ–™', 'é˜€é—¨', 'ç”µç¼†', 'ç®¡è·¯']):
                    result['material_requirements'].append({
                        'content': res['content'],
                        'score': res.get('rerank_score', res.get('score', 0)),
                        'query': f"{instrument_type}ææ–™è¦æ±‚"
                    })
            
            # æœç´¢å®‰å…¨è¦æ±‚ - ğŸ¯ å¢åŠ åˆ°3æ¡ï¼Œä¾›LLMç­›é€‰
            safety_results = self.advanced_search(f"{instrument_type}å®‰å…¨è¦æ±‚", instrument_type, top_k=3)
            for res in safety_results:
                if any(keyword in res['content'] for keyword in ['å®‰å…¨', 'é˜²æŠ¤', 'æ³¨æ„']):
                    result['safety_requirements'].append({
                        'content': res['content'],
                        'score': res.get('rerank_score', res.get('score', 0)),
                        'query': f"{instrument_type}å®‰å…¨è¦æ±‚"
                    })
            
            # æœç´¢ç»´æŠ¤è¦æ±‚ - ğŸ¯ å¢åŠ åˆ°3æ¡ï¼Œä¾›LLMç­›é€‰
            maintenance_results = self.advanced_search(f"{instrument_type}ç»´æŠ¤", instrument_type, top_k=3)
            for res in maintenance_results:
                if any(keyword in res['content'] for keyword in ['ç»´æŠ¤', 'ä¿å…»', 'æ£€ä¿®']):
                    result['maintenance_requirements'].append({
                        'content': res['content'],
                        'score': res.get('rerank_score', res.get('score', 0)),
                        'query': f"{instrument_type}ç»´æŠ¤"
                    })
            
            logger.info(f"ä¸º {instrument_type} ç”Ÿæˆç»¼åˆæ ‡å‡†ä¿¡æ¯: "
                       f"å®‰è£…{len(result['installation_methods'])}æ¡, "
                       f"ææ–™{len(result['material_requirements'])}æ¡, "
                       f"å®‰å…¨{len(result['safety_requirements'])}æ¡, "
                       f"ç»´æŠ¤{len(result['maintenance_requirements'])}æ¡")
        
        except Exception as e:
            logger.error(f"ç”Ÿæˆ {instrument_type} ç»¼åˆæ ‡å‡†ä¿¡æ¯å¤±è´¥: {str(e)}")
        
        return result

    def basic_retrieve(self, query: str, top_k: int = 5) -> List:
        """åŸºç¡€æ£€ç´¢æ–¹æ³•ï¼ˆä¸å«é‡æ’åºä¼˜åŒ–ï¼‰ï¼Œç”¨äºå¯¹æ¯”å®éªŒ"""
        try:
            # ä½¿ç”¨åŸºç¡€æ£€ç´¢å™¨è¿›è¡Œç®€å•çš„ç›¸ä¼¼åº¦æ£€ç´¢
            results = self.base_retriever.search_related_clauses(
                query, 
                top_k=top_k,
                min_similarity=0.5
            )
            
            # è½¬æ¢ä¸ºDocumentæ ¼å¼ä»¥ä¿æŒæ¥å£ä¸€è‡´æ€§
            from langchain.schema import Document
            documents = []
            for result in results:
                doc = Document(
                    page_content=result['content'],
                    metadata={
                        'score': result['score'],
                        'source': result.get('source', 'unknown'),
                        'section': result.get('section', '')
                    }
                )
                documents.append(doc)
            
            return documents
            
        except Exception as e:
            logger.error(f"åŸºç¡€æ£€ç´¢å¤±è´¥: {e}")
            return []
    
    def enhanced_retrieve(self, query: str, top_k: int = 5) -> Dict:
        """å¢å¼ºæ£€ç´¢æ–¹æ³•ï¼ˆåŒ…å«é‡æ’åºä¼˜åŒ–ï¼‰"""
        try:
            # ä½¿ç”¨é«˜çº§æœç´¢ï¼ˆåŒ…å«æŸ¥è¯¢æ‰©å±•å’Œé‡æ’åºï¼‰
            results = self.advanced_search(query, top_k=top_k)
            
            # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
            documents = []
            for result in results:
                doc_info = {
                    'content': result['content'],
                    'score': result.get('rerank_score', result['score']),
                    'metadata': {
                        'original_score': result.get('original_score', result['score']),
                        'rerank_score': result.get('rerank_score', result['score']),
                        'source_query': result.get('source_query', query),
                        'source': result.get('source', 'unknown'),
                        'section': result.get('section', '')
                    }
                }
                documents.append(doc_info)
            
            return {
                'documents': documents,
                'query': query,
                'total_results': len(documents),
                'enhanced': True
            }
            
        except Exception as e:
            logger.error(f"å¢å¼ºæ£€ç´¢å¤±è´¥: {e}")
            return {
                'documents': [],
                'query': query,
                'total_results': 0,
                'enhanced': False,
                'error': str(e)
            }

def test_enhanced_retriever():
    """æµ‹è¯•å¢å¼ºæ£€ç´¢å™¨"""
    print("ğŸš€ æµ‹è¯•å¢å¼ºRAGæ£€ç´¢å™¨")
    print("=" * 50)
    
    try:
        # åˆå§‹åŒ–å¢å¼ºæ£€ç´¢å™¨
        enhanced_retriever = EnhancedRAGRetriever()
        
        # æµ‹è¯•1ï¼šåŸºç¡€æŸ¥è¯¢å¢å¼º
        print("\nğŸ“‹ æµ‹è¯•1ï¼šåŸºç¡€æŸ¥è¯¢å¢å¼º")
        query = "çƒ­ç”µå¶å®‰è£…è¦æ±‚"
        enhanced_queries = enhanced_retriever.enhance_query(query)
        print(f"åŸå§‹æŸ¥è¯¢: {query}")
        print(f"å¢å¼ºæŸ¥è¯¢: {enhanced_queries}")
        
        # æµ‹è¯•2ï¼šé«˜çº§æœç´¢
        print("\nğŸ“‹ æµ‹è¯•2ï¼šé«˜çº§æœç´¢å¯¹æ¯”")
        basic_results = enhanced_retriever.base_retriever.search_related_clauses(query, top_k=3)
        enhanced_results = enhanced_retriever.advanced_search(query, "çƒ­ç”µå¶", top_k=3)
        
        print(f"åŸºç¡€æœç´¢ç»“æœæ•°: {len(basic_results)}")
        print(f"å¢å¼ºæœç´¢ç»“æœæ•°: {len(enhanced_results)}")
        
        if enhanced_results:
            best_result = enhanced_results[0]
            print(f"æœ€ä½³ç»“æœé‡æ’åºåˆ†æ•°: {best_result.get('rerank_score', 'N/A'):.3f}")
            print(f"åŸå§‹ç›¸ä¼¼åº¦åˆ†æ•°: {best_result.get('original_score', 'N/A'):.3f}")
        
        # æµ‹è¯•3ï¼šæ™ºèƒ½ä»ªè¡¨æœç´¢
        print("\nğŸ“‹ æµ‹è¯•3ï¼šæ™ºèƒ½ä»ªè¡¨æœç´¢")
        instrument_info = {
            'ä»ªè¡¨ç±»å‹': 'çƒ­ç”µå¶',
            'æµ‹é‡èŒƒå›´': '0-800â„ƒ',
            'å·¥è‰ºæ¡ä»¶': 'é«˜æ¸©è…èš€æ€§ä»‹è´¨'
        }
        
        intelligent_results = enhanced_retriever.intelligent_instrument_search(instrument_info)
        print(f"æ™ºèƒ½æœç´¢ç»“æœæ•°: {len(intelligent_results)}")
        
        for i, result in enumerate(intelligent_results[:2], 1):
            print(f"{i}. æŸ¥è¯¢: {result.get('search_query', 'N/A')}")
            print(f"   åˆ†æ•°: {result.get('rerank_score', result.get('score', 0)):.3f}")
            print(f"   å†…å®¹: {result['content'][:80]}...")
        
        print("\nâœ… å¢å¼ºæ£€ç´¢å™¨æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_enhanced_retriever()
 