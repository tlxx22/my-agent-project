"""
å¢å¼ºRAGæ£€ç´¢å™¨
é€šè¿‡æŸ¥è¯¢æ‰©å±•ã€é‡æ’åºã€é¢†åŸŸé€‚åº”ç­‰æŠ€æœ¯æå‡æ£€ç´¢è´¨é‡å’Œæ³›åŒ–æ€§
"""
import os
import re
import pickle
from typing import List, Dict, Tuple, Optional, Set
import logging
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from tools.build_index import DocumentIndexer
from tools.match_standard_clause import StandardClauseRetriever

logger = logging.getLogger(__name__)

class EnhancedRAGRetriever:
    """å¢å¼ºçš„RAGæ£€ç´¢å™¨"""
    
    def __init__(self, index_path: str = None):
        """åˆå§‹åŒ–å¢å¼ºæ£€ç´¢å™¨"""
        self.base_retriever = StandardClauseRetriever(index_path)
        self.instrument_vocabulary = self._build_instrument_vocabulary()
        self.semantic_enhancer = self._build_semantic_enhancer()
        
    def _build_instrument_vocabulary(self) -> Dict[str, Dict]:
        """æ„å»ºä»ªè¡¨é¢†åŸŸè¯æ±‡è¡¨å’Œè¯­ä¹‰å…³ç³»ï¼ˆä»LLMè¯†åˆ«ç»“æœåŠ¨æ€ç”Ÿæˆï¼‰"""
        try:
            # ä»LLMè¯†åˆ«ç»“æœä¸­è·å–ä»ªè¡¨ç±»å‹
            llm_types = self._load_llm_instrument_types()
            
            if not llm_types:
                logger.warning("âš ï¸ æœªæ‰¾åˆ°LLMè¯†åˆ«çš„ä»ªè¡¨ç±»å‹ï¼Œä½¿ç”¨åŸºæœ¬è¯æ±‡è¡¨")
                return self._build_basic_vocabulary()
            
            # åŸºäºLLMè¯†åˆ«çš„ç±»å‹åŠ¨æ€æ„å»ºè¯æ±‡è¡¨
            vocabulary = {}
            
            for instrument_type, info in llm_types.items():
                category = info.get('category', 'å…¶ä»–')
                
                # ä¸ºæ¯ä¸ªä»ªè¡¨ç±»å‹ç”Ÿæˆç›¸å…³è¯æ±‡
                vocab_entry = {
                    "main_types": [instrument_type],  # ä»¥LLMè¯†åˆ«çš„ç±»å‹ä¸ºä¸»
                    "related_terms": self._generate_related_terms(instrument_type, category),
                    "installation_terms": self._generate_installation_terms(instrument_type, category),
                    "materials": self._generate_material_terms(instrument_type, category)
                }
                
                vocabulary[instrument_type] = vocab_entry
            
            logger.info(f"ğŸ¤– åŸºäºLLMè¯†åˆ«ç»“æœæ„å»ºäº† {len(vocabulary)} ç§ä»ªè¡¨çš„è¯æ±‡è¡¨")
            return vocabulary
            
        except Exception as e:
            logger.warning(f"âš ï¸ åŠ¨æ€æ„å»ºè¯æ±‡è¡¨å¤±è´¥: {str(e)}ï¼Œä½¿ç”¨åŸºæœ¬è¯æ±‡è¡¨")
            return self._build_basic_vocabulary()
    
    def _load_llm_instrument_types(self) -> Dict:
        """åŠ è½½LLMè¯†åˆ«çš„ä»ªè¡¨ç±»å‹"""
        try:
            import json
            llm_types_file = "./data/llm_instrument_types.json"
            
            if os.path.exists(llm_types_file):
                with open(llm_types_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    return data.get('instrument_types', {})
            
            return {}
            
        except Exception as e:
            logger.warning(f"åŠ è½½LLMä»ªè¡¨ç±»å‹å¤±è´¥: {str(e)}")
            return {}
    
    def _generate_related_terms(self, instrument_type: str, category: str) -> List[str]:
        """åŸºäºä»ªè¡¨ç±»å‹å’Œç±»åˆ«åŠ¨æ€ç”Ÿæˆç›¸å…³æœ¯è¯­"""
        base_terms = []
        instrument_lower = instrument_type.lower()
        
        # åŸºäºç±»åˆ«ç”Ÿæˆé€šç”¨æœ¯è¯­
        if category == 'æ¸©åº¦':
            base_terms.extend(["æµ‹æ¸©", "æ„Ÿæ¸©", "æ¸©åº¦ä¼ æ„Ÿå™¨", "ä¿æŠ¤ç®¡", "æµ‹æ¸©ç‚¹"])
        elif category == 'å‹åŠ›':
            base_terms.extend(["å‹åŠ›æµ‹é‡", "å–å‹", "å‹åŠ›ä¼ æ„Ÿ", "å–å‹ç‚¹", "å¯¼å‹ç®¡"])
        elif category == 'æµé‡':
            base_terms.extend(["æµé‡æµ‹é‡", "æµé€Ÿ", "æµä½“", "ä»‹è´¨æµåŠ¨", "æµå‘"])
        elif category == 'æ¶²ä½' or category == 'ç‰©ä½':
            base_terms.extend(["æ¶²ä½æµ‹é‡", "ç‰©ä½", "ç•Œé¢", "æ¶²ä½èŒƒå›´"])
        elif category == 'æ§åˆ¶':
            base_terms.extend(["æ§åˆ¶", "è°ƒèŠ‚", "æ‰§è¡Œ", "å®šä½å™¨"])
        
        # åŸºäºå…·ä½“ç±»å‹åç§°ç”Ÿæˆç‰¹å®šæœ¯è¯­
        if 'çƒ­ç”µå¶' in instrument_lower:
            base_terms.extend(["çƒ­ç”µå¶", "PT100", "Kå‹", "æ¥çº¿ç›’"])
        elif 'å‹åŠ›' in instrument_lower:
            base_terms.extend(["è†œç‰‡", "å¼¹ç°§ç®¡", "ä¸‰é˜€ç»„", "ç¼“å†²å™¨"])
        elif 'æµé‡' in instrument_lower:
            base_terms.extend(["ç›´ç®¡æ®µ", "ä¸Šæ¸¸", "ä¸‹æ¸¸", "ç®¡é“ä¸­å¿ƒ"])
        elif 'æ¶²ä½' in instrument_lower:
            base_terms.extend(["æµ®å­", "æµ®çƒ", "å¯¼å‘ç®¡", "å–æºç®¡"])
        elif 'ç”µç£' in instrument_lower:
            base_terms.extend(["ç”µç£", "ç”µæ", "è¡¬é‡Œ", "æ³•å…°"])
        elif 'å·®å‹' in instrument_lower:
            base_terms.extend(["å·®å‹", "å‹å·®", "è†œç‰‡"])
        elif 'æµ®çƒ' in instrument_lower:
            base_terms.extend(["æµ®çƒ", "æµ®å­", "å¯¼æ³¢æ†"])
        
        return list(set(base_terms))  # å»é‡
    
    def _generate_installation_terms(self, instrument_type: str, category: str) -> List[str]:
        """ç”Ÿæˆå®‰è£…ç›¸å…³æœ¯è¯­"""
        installation_terms = ["å®‰è£…ä½ç½®", "å®‰è£…é«˜åº¦", "å®‰è£…æ–¹å‘", "å›ºå®š", "æ”¯æ’‘"]
        
        instrument_lower = instrument_type.lower()
        
        # åŸºäºä»ªè¡¨ç±»å‹æ·»åŠ ç‰¹å®šå®‰è£…æœ¯è¯­
        if 'æ¸©åº¦' in category.lower() or 'çƒ­ç”µå¶' in instrument_lower:
            installation_terms.extend(["æ’å…¥æ·±åº¦", "ä¿æŠ¤å¥—", "æ¥çº¿ç›’"])
        elif 'å‹åŠ›' in category.lower() or 'å‹åŠ›' in instrument_lower:
            installation_terms.extend(["å–å‹ç‚¹", "å¯¼å‹ç®¡", "ä¸‰é˜€ç»„"])
        elif 'æµé‡' in category.lower() or 'æµé‡' in instrument_lower:
            installation_terms.extend(["ç›´ç®¡æ®µ", "ä¸Šæ¸¸", "ä¸‹æ¸¸", "ç®¡é“ä¸­å¿ƒ"])
        elif 'æ¶²ä½' in category.lower() or 'æ¶²ä½' in instrument_lower:
            installation_terms.extend(["å‚ç›´å®‰è£…", "å¯¼å‘ç®¡", "æ¶²ä½èŒƒå›´"])
        elif 'é˜€' in instrument_lower or 'æ§åˆ¶' in category.lower():
            installation_terms.extend(["é˜€é—¨æ–¹å‘", "æµå‘", "è¿æ¥æ–¹å¼"])
        
        return list(set(installation_terms))
    
    def _generate_material_terms(self, instrument_type: str, category: str) -> List[str]:
        """ç”Ÿæˆææ–™ç›¸å…³æœ¯è¯­"""
        base_materials = ["ä¸é”ˆé’¢", "ç¢³é’¢", "é‡‘å±å¥—ç®¡"]
        
        instrument_lower = instrument_type.lower()
        
        # åŸºäºä»ªè¡¨ç±»å‹æ·»åŠ ç‰¹å®šææ–™
        if 'æ¸©åº¦' in category.lower():
            base_materials.extend(["é™¶ç“·", "é‡‘å±å¥—ç®¡", "ä¿æŠ¤ç®¡"])
        elif 'å‹åŠ›' in category.lower():
            base_materials.extend(["ä¸é”ˆé’¢ç®¡", "é“œç®¡", "èšå››æ°Ÿä¹™çƒ¯"])
        elif 'æµé‡' in category.lower():
            base_materials.extend(["è¡¬é‡Œ", "ç”µæ", "æ³•å…°"])
        elif 'æ¶²ä½' in category.lower():
            base_materials.extend(["æµ®ç­’", "å¯¼æ³¢æ†", "ç¼†ç»³"])
        elif 'é˜€' in instrument_lower:
            base_materials.extend(["é˜€ä½“ææ–™", "å¯†å°ææ–™", "å¼¹ç°§"])
        
        return list(set(base_materials))
    
    def _build_basic_vocabulary(self) -> Dict[str, Dict]:
        """åŸºæœ¬è¯æ±‡è¡¨ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        return {
            "é€šç”¨ä»ªè¡¨": {
                "main_types": ["ä»ªè¡¨", "ä¼ æ„Ÿå™¨", "å˜é€å™¨", "è®¡é‡å™¨"],
                "related_terms": ["æµ‹é‡", "æ£€æµ‹", "ç›‘æµ‹", "ä¼ æ„Ÿ", "ä¿¡å·"],
                "installation_terms": ["å®‰è£…ä½ç½®", "å®‰è£…è¦æ±‚", "å›ºå®šæ–¹å¼", "è¿æ¥"],
                "materials": ["ä¸é”ˆé’¢", "é‡‘å±", "ææ–™é€‰æ‹©"]
            }
        }
    
    def _build_semantic_enhancer(self) -> Dict[str, List[str]]:
        """æ„å»ºè¯­ä¹‰å¢å¼ºæ˜ å°„"""
        return {
            "å®‰è£…": ["å®‰è£…", "å®‰è£…è¦æ±‚", "å®‰è£…æ–¹æ³•", "å®‰è£…ä½ç½®", "å®‰è£…é«˜åº¦", "å®‰è£…æ–¹å‘", "å›ºå®š", "æ”¯æ’‘"],
            "ææ–™": ["ææ–™", "æè´¨", "é€‰æ", "ææ–™è¦æ±‚", "ç®¡è·¯ææ–™", "é˜€é—¨ææ–™", "ç”µç¼†"],
            "è¿æ¥": ["è¿æ¥", "æ¥çº¿", "é…ç®¡", "é…çº¿", "æ¥å¤´", "æ³•å…°", "èºçº¹"],
            "ä¿æŠ¤": ["ä¿æŠ¤", "é˜²æŠ¤", "ä¿æŠ¤ç®¡", "ä¿æŠ¤å¥—", "é˜²è…", "é˜²çˆ†", "å¯†å°"],
            "ç»´æŠ¤": ["ç»´æŠ¤", "ä¿å…»", "æ£€ä¿®", "æ ¡å‡†", "æ¸…æ´—", "æ›´æ¢"],
            "å®‰å…¨": ["å®‰å…¨", "å®‰å…¨è¦æ±‚", "æ³¨æ„äº‹é¡¹", "é˜²æŠ¤æªæ–½", "æ¥åœ°", "ç»ç¼˜"]
        }

    def enhance_query(self, query: str, instrument_type: str = None) -> List[str]:
        """æŸ¥è¯¢å¢å¼ºï¼šåŸºäºé¢†åŸŸçŸ¥è¯†æ‰©å±•æŸ¥è¯¢"""
        enhanced_queries = [query]  # ä¿ç•™åŸå§‹æŸ¥è¯¢
        
        # 1. è‡ªåŠ¨è¯†åˆ«ä»ªè¡¨ç±»å‹ï¼ˆå¦‚æœæœªæä¾›ï¼‰
        if not instrument_type:
            instrument_type = self._identify_instrument_type(query)
        
        # 2. åŸºäºä»ªè¡¨ç±»å‹æ·»åŠ ç›¸å…³è¯æ±‡
        if instrument_type:
            vocab = self._get_instrument_vocabulary(instrument_type)
            if vocab:
                for main_type in vocab.get("main_types", []):
                    if main_type.lower() in query.lower():
                        for term in vocab.get("related_terms", [])[:3]:
                            enhanced_queries.append(f"{main_type} {term}")
                
                if any(keyword in query.lower() for keyword in ["å®‰è£…", "å®‰è£…è¦æ±‚", "å®‰è£…æ–¹æ³•"]):
                    for install_term in vocab.get("installation_terms", [])[:2]:
                        enhanced_queries.append(f"{instrument_type} {install_term}")
        
        # 3. åŸºäºæŸ¥è¯¢æ„å›¾æ·»åŠ è¯­ä¹‰æ‰©å±•
        for semantic_key, expansions in self.semantic_enhancer.items():
            if semantic_key in query:
                for expansion in expansions[:2]:
                    if expansion != semantic_key:
                        enhanced_query = query.replace(semantic_key, expansion)
                        enhanced_queries.append(enhanced_query)
        
        # 4. å»é‡å¹¶é™åˆ¶æŸ¥è¯¢æ•°é‡
        unique_queries = []
        seen = set()
        for q in enhanced_queries:
            if q.lower() not in seen:
                unique_queries.append(q)
                seen.add(q.lower())
        
        return unique_queries[:5]  # æœ€å¤šè¿”å›5ä¸ªæŸ¥è¯¢

    def _identify_instrument_type(self, query: str) -> Optional[str]:
        """åŸºäºæŸ¥è¯¢å†…å®¹è‡ªåŠ¨è¯†åˆ«ä»ªè¡¨ç±»å‹"""
        query_lower = query.lower()
        
        for category, vocab in self.instrument_vocabulary.items():
            for main_type in vocab.get("main_types", []):
                if main_type.lower() in query_lower:
                    return main_type
            
            for related_term in vocab.get("related_terms", []):
                if related_term.lower() in query_lower:
                    return vocab["main_types"][0] if vocab["main_types"] else None
        
        return None
    
    def _get_instrument_vocabulary(self, instrument_type: str) -> Optional[Dict]:
        """è·å–ç‰¹å®šä»ªè¡¨ç±»å‹çš„è¯æ±‡ä¿¡æ¯"""
        for category, vocab in self.instrument_vocabulary.items():
            if instrument_type in vocab.get("main_types", []):
                return vocab
        return None

    def advanced_search(self, query: str, instrument_type: str = None, top_k: int = 5) -> List[Dict]:
        """
        å¢å¼ºæœç´¢ï¼šç»“åˆæŸ¥è¯¢æ‰©å±•å’Œé‡æ’åº
        
        Args:
            query: æŸ¥è¯¢å­—ç¬¦ä¸²
            instrument_type: ä»ªè¡¨ç±»å‹
            top_k: è¿”å›ç»“æœæ•°é‡
        
        Returns:
            é‡æ’åºåçš„æœç´¢ç»“æœ
        """
        # 1. æŸ¥è¯¢å¢å¼º
        enhanced_queries = self.enhance_query(query, instrument_type)
        
        # 2. å¤šæŸ¥è¯¢æ£€ç´¢
        all_results = []
        seen_content = set()
        
        for i, enhanced_query in enumerate(enhanced_queries):
            # ä¸ºä¸åŒæŸ¥è¯¢è®¾ç½®ä¸åŒçš„æƒé‡
            weight = 1.0 - (i * 0.1)  # åŸå§‹æŸ¥è¯¢æƒé‡æœ€é«˜
            
            results = self.base_retriever.search_related_clauses(
                enhanced_query, 
                top_k=top_k * 2,  # è·å–æ›´å¤šå€™é€‰ç»“æœ
                min_similarity=0.4  # é™ä½åˆå§‹é˜ˆå€¼ï¼Œåç»­é‡æ’åº
            )
            
            for result in results:
                content = result['content']
                if content not in seen_content:
                    seen_content.add(content)
                    # æ·»åŠ æŸ¥è¯¢æƒé‡å’Œæ¥æºä¿¡æ¯
                    result['query_weight'] = weight
                    result['source_query'] = enhanced_query
                    all_results.append(result)
        
        # 3. é‡æ’åº
        reranked_results = self._rerank_results(all_results, query, instrument_type)
        
        return reranked_results[:top_k]
    
    def _rerank_results(self, results: List[Dict], original_query: str, instrument_type: str = None) -> List[Dict]:
        """ç»“æœé‡æ’åºï¼šåŸºäºå¤šä¸ªå› ç´ é‡æ–°è®¡ç®—ç›¸å…³æ€§åˆ†æ•°"""
        for result in results:
            content = result['content']
            original_score = result['score']
            query_weight = result.get('query_weight', 1.0)
            
            # é‡æ–°è®¡ç®—ç»¼åˆåˆ†æ•°
            rerank_score = self._calculate_rerank_score(
                content, original_query, instrument_type, original_score, query_weight
            )
            
            result['rerank_score'] = rerank_score
            result['original_score'] = original_score
        
        # æŒ‰é‡æ’åºåˆ†æ•°æ’åº
        results.sort(key=lambda x: x['rerank_score'], reverse=True)
        
        return results
    
    def _calculate_rerank_score(self, content: str, query: str, instrument_type: str, 
                               original_score: float, query_weight: float) -> float:
        """
        è®¡ç®—é‡æ’åºåˆ†æ•°
        
        ç»¼åˆè€ƒè™‘ï¼š
        1. åŸå§‹å‘é‡ç›¸ä¼¼åº¦
        2. æŸ¥è¯¢æƒé‡
        3. ä»ªè¡¨ç±»å‹åŒ¹é…åº¦
        4. å…³é”®è¯åŒ¹é…åº¦
        5. å†…å®¹è´¨é‡è¯„åˆ†
        """
        content_lower = content.lower()
        query_lower = query.lower()
        
        # 1. åŸºç¡€åˆ†æ•°ï¼ˆåŸå§‹ç›¸ä¼¼åº¦ * æŸ¥è¯¢æƒé‡ï¼‰
        base_score = original_score * query_weight
        
        # 2. ä»ªè¡¨ç±»å‹åŒ¹é…åŠ åˆ†
        type_bonus = 0.0
        if instrument_type:
            vocab = self._get_instrument_vocabulary(instrument_type)
            if vocab:
                # ç²¾ç¡®åŒ¹é…ä¸»è¦ç±»å‹
                if instrument_type.lower() in content_lower:
                    type_bonus += 0.2
                
                # åŒ¹é…ç›¸å…³æœ¯è¯­
                related_matches = sum(1 for term in vocab.get("related_terms", []) 
                                    if term.lower() in content_lower)
                type_bonus += min(related_matches * 0.05, 0.15)
        
        # 3. æŸ¥è¯¢å…³é”®è¯åŒ¹é…åŠ åˆ†
        query_words = set(query_lower.split())
        content_words = set(content_lower.split())
        keyword_overlap = len(query_words.intersection(content_words)) / len(query_words) if query_words else 0
        keyword_bonus = keyword_overlap * 0.15
        
        # 4. å†…å®¹è´¨é‡è¯„åˆ†
        quality_score = self._assess_content_quality(content, query)
        
        # 5. åå‘æƒ©ç½šï¼šé™ä½æ— å…³å†…å®¹åˆ†æ•°
        penalty = self._calculate_irrelevance_penalty(content, query, instrument_type)
        
        # ç»¼åˆåˆ†æ•°è®¡ç®—
        final_score = base_score + type_bonus + keyword_bonus + quality_score - penalty
        
        return max(0.0, min(1.0, final_score))  # é™åˆ¶åœ¨[0,1]èŒƒå›´å†…
    
    def _assess_content_quality(self, content: str, query: str) -> float:
        """è¯„ä¼°å†…å®¹è´¨é‡"""
        quality_score = 0.0
        
        # é•¿åº¦é€‚ä¸­æ€§ï¼ˆå¤ªçŸ­æˆ–å¤ªé•¿éƒ½å‡åˆ†ï¼‰
        length = len(content)
        if 50 <= length <= 300:
            quality_score += 0.05
        elif length < 20:
            quality_score -= 0.1
        
        # ç»“æ„åŒ–ç¨‹åº¦ï¼ˆåŒ…å«æ¡æ¬¾å·ã€ç¼–å·ç­‰ï¼‰
        if re.search(r'ç¬¬\s*\d+\.\d+\.\d+\s*æ¡', content):
            quality_score += 0.1
        elif re.search(r'\d+[ã€ï¼]\s*', content):
            quality_score += 0.05
        
        # æŠ€æœ¯æœ¯è¯­å¯†åº¦
        technical_terms = ["å®‰è£…", "è¦æ±‚", "è§„å®š", "åº”", "å®œ", "ä¸åº”", "å¿…é¡»", "ç¦æ­¢"]
        term_count = sum(1 for term in technical_terms if term in content)
        quality_score += min(term_count * 0.02, 0.1)
        
        return quality_score
    
    def _calculate_irrelevance_penalty(self, content: str, query: str, instrument_type: str) -> float:
        """è®¡ç®—æ— å…³å†…å®¹çš„æƒ©ç½šåˆ†æ•°"""
        penalty = 0.0
        content_lower = content.lower()
        
        # å¦‚æœæŒ‡å®šäº†ä»ªè¡¨ç±»å‹ï¼Œæ£€æŸ¥æ˜¯å¦åŒ…å«å…¶ä»–ä¸ç›¸å…³çš„ä»ªè¡¨ç±»å‹
        if instrument_type:
            other_instruments = []
            for category, vocab in self.instrument_vocabulary.items():
                for main_type in vocab.get("main_types", []):
                    if main_type != instrument_type:
                        other_instruments.append(main_type.lower())
            
            # å¦‚æœå†…å®¹å¼ºçƒˆæŒ‡å‘å…¶ä»–ä»ªè¡¨ç±»å‹ï¼Œå¢åŠ æƒ©ç½š
            other_type_mentions = sum(1 for other_type in other_instruments 
                                    if other_type in content_lower)
            if other_type_mentions >= 2:
                penalty += 0.3
            elif other_type_mentions == 1:
                penalty += 0.1
        
        # è¿‡äºé€šç”¨çš„å†…å®¹æƒ©ç½š
        generic_patterns = [
            r'^[^ã€‚]{0,30}$',  # è¿‡çŸ­ä¸”æ²¡æœ‰å¥å·
            r'ä¸€èˆ¬è§„å®š',
            r'æ€»åˆ™',
            r'åŸºæœ¬è¦æ±‚'
        ]
        
        for pattern in generic_patterns:
            if re.search(pattern, content_lower):
                penalty += 0.1
                break
        
        return penalty

    def intelligent_instrument_search(self, instrument_info: Dict) -> List[Dict]:
        """
        æ™ºèƒ½ä»ªè¡¨æœç´¢ï¼šåŸºäºè¡¨æ ¼ä¸­çš„ä»ªè¡¨ä¿¡æ¯è¿›è¡Œæ™ºèƒ½æœç´¢
        å¯¹ä¸åŒä»ªè¡¨ç±»å‹å…·æœ‰è‰¯å¥½çš„æ³›åŒ–æ€§
        
        Args:
            instrument_info: ä»ªè¡¨ä¿¡æ¯å­—å…¸ï¼ŒåŒ…å«ç±»å‹ã€æµ‹é‡èŒƒå›´ã€å·¥è‰ºæ¡ä»¶ç­‰
        
        Returns:
            ç›¸å…³çš„å®‰è£…è§„èŒƒåˆ—è¡¨
        """
        instrument_type = instrument_info.get('ä»ªè¡¨ç±»å‹', instrument_info.get('type', ''))
        measure_range = instrument_info.get('æµ‹é‡èŒƒå›´', instrument_info.get('range', ''))
        process_condition = instrument_info.get('å·¥è‰ºæ¡ä»¶', instrument_info.get('condition', ''))
        
        # æ„å»ºæ™ºèƒ½æŸ¥è¯¢
        search_queries = []
        
        # 1. åŸºç¡€æŸ¥è¯¢
        if instrument_type:
            search_queries.append(f"{instrument_type}å®‰è£…")
            search_queries.append(f"{instrument_type}å®‰è£…è¦æ±‚")
        
        # 2. åŸºäºæµ‹é‡èŒƒå›´çš„æŸ¥è¯¢
        if measure_range:
            # æå–æ¸©åº¦ã€å‹åŠ›ç­‰å…³é”®ä¿¡æ¯
            if 'â„ƒ' in measure_range or 'Â°C' in measure_range:
                if 'é«˜æ¸©' in measure_range or any(temp in measure_range for temp in ['400', '500', '600']):
                    search_queries.append(f"{instrument_type}é«˜æ¸©å®‰è£…")
                if 'ä½æ¸©' in measure_range or '-' in measure_range:
                    search_queries.append(f"{instrument_type}ä½æ¸©å®‰è£…")
            
            if 'MPa' in measure_range or 'kPa' in measure_range:
                if any(pressure in measure_range for pressure in ['é«˜å‹', '10', '20', '50']):
                    search_queries.append(f"{instrument_type}é«˜å‹å®‰è£…")
        
        # 3. åŸºäºå·¥è‰ºæ¡ä»¶çš„æŸ¥è¯¢
        if process_condition:
            if 'è…èš€' in process_condition:
                search_queries.append(f"{instrument_type}é˜²è…ææ–™")
            if 'é«˜æ¸©' in process_condition:
                search_queries.append(f"{instrument_type}é«˜æ¸©ä¿æŠ¤")
            if 'æŒ¯åŠ¨' in process_condition:
                search_queries.append(f"{instrument_type}é˜²æŒ¯å®‰è£…")
        
        # 4. æ‰§è¡Œæœç´¢å¹¶åˆå¹¶ç»“æœ
        all_results = []
        seen_content = set()
        
        for query in search_queries:
            results = self.advanced_search(query, instrument_type, top_k=3)
            for result in results:
                if result['content'] not in seen_content:
                    seen_content.add(result['content'])
                    result['search_query'] = query
                    all_results.append(result)
        
        # æŒ‰é‡æ’åºåˆ†æ•°æ’åº
        all_results.sort(key=lambda x: x.get('rerank_score', x.get('score', 0)), reverse=True)
        
        return all_results[:5]  # è¿”å›å‰5ä¸ªæœ€ç›¸å…³çš„ç»“æœ

def test_enhanced_retriever():
    """æµ‹è¯•å¢å¼ºæ£€ç´¢å™¨"""
    print("ğŸš€ æµ‹è¯•å¢å¼ºRAGæ£€ç´¢å™¨")
    print("=" * 50)
    
    try:
        # åˆå§‹åŒ–å¢å¼ºæ£€ç´¢å™¨
        enhanced_retriever = EnhancedRAGRetriever()
        
        # æµ‹è¯•1ï¼šåŸºç¡€æŸ¥è¯¢å¢å¼º
        print("\nğŸ“‹ æµ‹è¯•1ï¼šåŸºç¡€æŸ¥è¯¢å¢å¼º")
        query = "çƒ­ç”µå¶å®‰è£…è¦æ±‚"
        enhanced_queries = enhanced_retriever.enhance_query(query)
        print(f"åŸå§‹æŸ¥è¯¢: {query}")
        print(f"å¢å¼ºæŸ¥è¯¢: {enhanced_queries}")
        
        # æµ‹è¯•2ï¼šé«˜çº§æœç´¢
        print("\nğŸ“‹ æµ‹è¯•2ï¼šé«˜çº§æœç´¢å¯¹æ¯”")
        basic_results = enhanced_retriever.base_retriever.search_related_clauses(query, top_k=3)
        enhanced_results = enhanced_retriever.advanced_search(query, "çƒ­ç”µå¶", top_k=3)
        
        print(f"åŸºç¡€æœç´¢ç»“æœæ•°: {len(basic_results)}")
        print(f"å¢å¼ºæœç´¢ç»“æœæ•°: {len(enhanced_results)}")
        
        if enhanced_results:
            best_result = enhanced_results[0]
            print(f"æœ€ä½³ç»“æœé‡æ’åºåˆ†æ•°: {best_result.get('rerank_score', 'N/A'):.3f}")
            print(f"åŸå§‹ç›¸ä¼¼åº¦åˆ†æ•°: {best_result.get('original_score', 'N/A'):.3f}")
        
        # æµ‹è¯•3ï¼šæ™ºèƒ½ä»ªè¡¨æœç´¢
        print("\nğŸ“‹ æµ‹è¯•3ï¼šæ™ºèƒ½ä»ªè¡¨æœç´¢")
        instrument_info = {
            'ä»ªè¡¨ç±»å‹': 'çƒ­ç”µå¶',
            'æµ‹é‡èŒƒå›´': '0-800â„ƒ',
            'å·¥è‰ºæ¡ä»¶': 'é«˜æ¸©è…èš€æ€§ä»‹è´¨'
        }
        
        intelligent_results = enhanced_retriever.intelligent_instrument_search(instrument_info)
        print(f"æ™ºèƒ½æœç´¢ç»“æœæ•°: {len(intelligent_results)}")
        
        for i, result in enumerate(intelligent_results[:2], 1):
            print(f"{i}. æŸ¥è¯¢: {result.get('search_query', 'N/A')}")
            print(f"   åˆ†æ•°: {result.get('rerank_score', result.get('score', 0)):.3f}")
            print(f"   å†…å®¹: {result['content'][:80]}...")
        
        print("\nâœ… å¢å¼ºæ£€ç´¢å™¨æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_enhanced_retriever()
 