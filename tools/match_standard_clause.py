"""
å®‰è£…è§„èŒƒæ£€ç´¢å·¥å…·
ä»å‘é‡æ•°æ®åº“ä¸­æ£€ç´¢ä¸ä»ªè¡¨ç±»å‹ç›¸å…³çš„è§„èŒƒæ®µè½
"""
import os
import pickle
from typing import List, Dict, Tuple, Optional
import logging
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer
from tools.build_index import DocumentIndexer

# é…ç½®å¸¸é‡
FAISS_INDEX_PATH = "./data/indexes/instrument_standards.index"

logger = logging.getLogger(__name__)

class StandardClauseRetriever:
    """æ ‡å‡†è§„èŒƒæ£€ç´¢å™¨"""
    
    def __init__(self, index_path: str = None):
        """
        åˆå§‹åŒ–æ£€ç´¢å™¨
        
        Args:
            index_path: å‘é‡ç´¢å¼•æ–‡ä»¶è·¯å¾„
        """
        self.index_path = index_path or FAISS_INDEX_PATH
        self.indexer = DocumentIndexer()
        self.is_loaded = False
        
    def load_index(self) -> bool:
        """
        åŠ è½½å‘é‡ç´¢å¼•
        
        Returns:
            æ˜¯å¦åŠ è½½æˆåŠŸ
        """
        if self.is_loaded:
            return True
        
        if not os.path.exists(self.index_path):
            logger.error(f"ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨: {self.index_path}")
            return False
        
        success = self.indexer.load_index(self.index_path)
        self.is_loaded = success
        return success
    
    def search_related_clauses(self, query: str, top_k: int = 5, min_similarity: float = 0.5) -> List[Dict]:
        """
        æœç´¢ä¸æŸ¥è¯¢ç›¸å…³çš„è§„èŒƒæ¡æ¬¾
        
        Args:
            query: æŸ¥è¯¢å­—ç¬¦ä¸²
            top_k: è¿”å›æœ€ç›¸å…³çš„kä¸ªç»“æœ
            min_similarity: æœ€å°ç›¸ä¼¼åº¦é˜ˆå€¼(é™ä½åˆ°0.5ä»¥æé«˜å¬å›ç‡)
        
        Returns:
            ç›¸å…³æ¡æ¬¾åˆ—è¡¨ï¼Œæ¯ä¸ªæ¡æ¬¾åŒ…å«content, score, metadata
        """
        if not self.is_loaded:
            if not self.load_index():
                return []
        
        try:
            # å¯¹æŸ¥è¯¢è¿›è¡ŒåµŒå…¥
            query_embedding = self.indexer.model.encode([query])
            
            # æ ‡å‡†åŒ–æŸ¥è¯¢å‘é‡
            faiss.normalize_L2(query_embedding)
            
            # åœ¨ç´¢å¼•ä¸­æœç´¢æ›´å¤šå€™é€‰ç»“æœ
            search_k = min(top_k * 4, 30)  # ğŸ¯ ä»3å€å¢åŠ åˆ°4å€ï¼Œæœ€å¤§ä»20å¢åŠ åˆ°30ï¼Œè·å–æ›´å¤šå€™é€‰ç»“æœè¿›è¡Œè´¨é‡è¿‡æ»¤
            scores, indices = self.indexer.index.search(query_embedding.astype(np.float32), search_k)
            
            results = []
            for i, (score, idx) in enumerate(zip(scores[0], indices[0])):
                if idx == -1:  # æ— æ•ˆç´¢å¼•
                    continue
                
                if score < min_similarity:  # ç›¸ä¼¼åº¦å¤ªä½
                    continue
                
                content = self.indexer.documents[idx]
                
                # è´¨é‡è¿‡æ»¤ï¼šæ’é™¤æ˜æ˜¾ä¸ç›¸å…³çš„å†…å®¹
                if self._is_low_quality_match(content, query):
                    continue
                
                result = {
                    'content': content,
                    'score': float(score),
                    'metadata': self.indexer.metadata[idx],
                    'rank': i + 1
                }
                results.append(result)
                
                # è¾¾åˆ°ç›®æ ‡æ•°é‡å°±åœæ­¢
                if len(results) >= top_k:
                    break
            
            logger.info(f"æŸ¥è¯¢ '{query}' æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³æ¡æ¬¾")
            return results
            
        except Exception as e:
            logger.error(f"æœç´¢è§„èŒƒæ¡æ¬¾æ—¶å‡ºé”™: {str(e)}")
            return []
    
    def _is_low_quality_match(self, content: str, query: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦ä¸ºä½è´¨é‡åŒ¹é…
        
        Args:
            content: åŒ¹é…çš„å†…å®¹
            query: æŸ¥è¯¢è¯
        
        Returns:
            Trueè¡¨ç¤ºä½è´¨é‡ï¼Œåº”è¯¥è¿‡æ»¤
        """
        # è¿‡æ»¤è¿‡çŸ­çš„å†…å®¹
        if len(content.strip()) < 15:
            return True
        
        # è¿‡æ»¤åªæœ‰æ ‡é¢˜æ²¡æœ‰å®è´¨å†…å®¹çš„æ¡æ¬¾
        title_only_patterns = [
            r'^[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d+]+[ã€ï¼\.\s]*[^ã€‚ï¼ï¼Ÿ]*$',  # åªæœ‰ç¼–å·å’ŒçŸ­æ ‡é¢˜
            r'^ç¬¬\s*\d+\.\d+\.\d+\s*æ¡\s*[^ã€‚ï¼ï¼Ÿ]{0,20}$',  # åªæœ‰æ¡æ¬¾å·å’ŒçŸ­æ ‡é¢˜
            r'^[^ã€‚ï¼ï¼Ÿ]{0,30}$',  # å†…å®¹å¤ªçŸ­ï¼Œå¯èƒ½åªæ˜¯æ ‡é¢˜ç‰‡æ®µ
        ]
        
        for pattern in title_only_patterns:
            import re
            if re.match(pattern, content.strip()):
                return True
        
        # è¿‡æ»¤æ˜æ˜¾ä¸ç›¸å…³çš„å†…å®¹ï¼ˆé€šè¿‡å…³é”®è¯æ£€æŸ¥ï¼‰
        query_lower = query.lower()
        content_lower = content.lower()
        
        # æ›´ä¸¥æ ¼çš„ä»ªè¡¨ç±»å‹åŒ¹é…æ£€æŸ¥
        instrument_type_map = {
            'æ¸©åº¦': ['æ¸©åº¦', 'çƒ­ç”µå¶', 'çƒ­ç”µé˜»', 'æ¸©åº¦è®¡', 'æ„Ÿæ¸©'],
            'å‹åŠ›': ['å‹åŠ›', 'å‹åŠ›è¡¨', 'å‹åŠ›å˜é€å™¨', 'å‹åŠ›å–æº'],
            'æµé‡': ['æµé‡', 'æµé‡è®¡', 'æµé‡å˜é€å™¨', 'è½¬å­æµé‡', 'ç”µç£æµé‡'],
            'æ¶²ä½': ['æ¶²ä½', 'æ¶²ä½è®¡', 'æ¶²ä½å˜é€å™¨', 'æµ®ç­’', 'æµ®ç®€', 'ç‰©ä½'],
            'æ§åˆ¶': ['æ§åˆ¶', 'æ§åˆ¶ç®±', 'æ§åˆ¶æŸœ', 'ç”µåŠ¨é—¨', 'è°ƒèŠ‚é˜€'],
            'è°ƒèŠ‚é˜€': ['è°ƒèŠ‚é˜€', 'æ‰§è¡Œæœºæ„', 'é˜€ä½“', 'æ°”åŠ¨'],
            'ç”µåŠ¨é—¨': ['ç”µåŠ¨é—¨', 'æ§åˆ¶ç®±', 'è”é”', 'å¼€å…³']
        }
        
        # ç¡®å®šæŸ¥è¯¢çš„ä»ªè¡¨ç±»å‹
        query_type = None
        for inst_type, keywords in instrument_type_map.items():
            if any(kw in query_lower for kw in keywords):
                query_type = inst_type
                break
        
        # å¦‚æœç¡®å®šäº†æŸ¥è¯¢ç±»å‹ï¼Œæ£€æŸ¥å†…å®¹æ˜¯å¦åŒ¹é…
        if query_type:
            type_keywords = instrument_type_map[query_type]
            content_matches_type = any(kw in content_lower for kw in type_keywords)
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å…¶ä»–ä»ªè¡¨ç±»å‹ï¼ˆäº¤å‰æ±¡æŸ“ï¼‰
            other_types = [t for t in instrument_type_map.keys() if t != query_type]
            has_cross_contamination = False
            
            for other_type in other_types:
                other_keywords = instrument_type_map[other_type]
                # å¦‚æœå†…å®¹å¼ºçƒˆæŒ‡å‘å…¶ä»–ä»ªè¡¨ç±»å‹ï¼Œåˆ™è®¤ä¸ºæ˜¯äº¤å‰æ±¡æŸ“
                other_matches = sum(1 for kw in other_keywords if kw in content_lower)
                if other_matches >= 2:  # åŒ…å«2ä¸ªæˆ–ä»¥ä¸Šå…¶ä»–ç±»å‹å…³é”®è¯
                    has_cross_contamination = True
                    break
            
            # å¦‚æœä¸åŒ¹é…ç›®æ ‡ç±»å‹ï¼Œæˆ–è€…æœ‰ä¸¥é‡äº¤å‰æ±¡æŸ“ï¼Œåˆ™è¿‡æ»¤
            if not content_matches_type or has_cross_contamination:
                return True
            
            # é¢å¤–æ£€æŸ¥ï¼šå¦‚æœæŸ¥è¯¢æ˜¯å…·ä½“ä»ªè¡¨ç±»å‹ï¼Œå†…å®¹å´æ˜¯é€šç”¨æ¡æ¬¾ï¼Œä¹Ÿè¿‡æ»¤
            if query_type in ['æ¸©åº¦', 'å‹åŠ›', 'æµé‡', 'æ¶²ä½']:
                generic_phrases = ['ä»ªè¡¨å®‰è£…', 'å®‰è£…è§„åˆ™', 'é€šç”¨è¦æ±‚', 'ä¸€èˆ¬è§„å®š']
                if any(phrase in content_lower for phrase in generic_phrases) and len(content) < 100:
                    return True
        
        return False
    
    def search_by_instrument_type(self, instrument_type: str, top_k: int = 5) -> List[Dict]:
        """
        æ ¹æ®ä»ªè¡¨ç±»å‹æœç´¢ç›¸å…³å®‰è£…è§„èŒƒ
        
        Args:
            instrument_type: ä»ªè¡¨ç±»å‹ï¼ˆå¦‚ï¼šçƒ­ç”µå¶ã€å‹åŠ›è¡¨ç­‰ï¼‰
            top_k: è¿”å›ç»“æœæ•°é‡
        
        Returns:
            ç›¸å…³è§„èŒƒæ¡æ¬¾åˆ—è¡¨
        """
        # ä¼˜åŒ–æŸ¥è¯¢ç­–ç•¥ï¼šæ›´ç²¾ç¡®çš„æŸ¥è¯¢è¯ç»„åˆ
        queries = [
            f"{instrument_type}å®‰è£…",
            f"{instrument_type}å®‰è£…è¦æ±‚",
            f"{instrument_type}å®‰è£…æ–¹æ³•", 
            f"{instrument_type}å®‰è£…ä½ç½®",
            f"{instrument_type}å®‰è£…è§„èŒƒ"
        ]
        
        all_results = []
        seen_contents = set()  # é¿å…é‡å¤ç»“æœ
        
        for query in queries:
            # æ¯ä¸ªæŸ¥è¯¢æœ€å¤šå–2ä¸ªç»“æœï¼Œæé«˜ç²¾åº¦  
            results = self.search_related_clauses(query, top_k=2, min_similarity=0.5)
            
            for result in results:
                content = result['content']
                if content not in seen_contents:
                    seen_contents.add(content)
                    result['query'] = query
                    all_results.append(result)
        
        # æŒ‰ç›¸ä¼¼åº¦åˆ†æ•°æ’åº
        all_results.sort(key=lambda x: x['score'], reverse=True)
        
        # è¿”å›å‰top_kä¸ªç»“æœ
        return all_results[:top_k]
    
    def search_installation_materials(self, instrument_type: str, top_k: int = 3) -> List[Dict]:
        """
        æœç´¢ä¸ä»ªè¡¨ç±»å‹ç›¸å…³çš„å®‰è£…ææ–™è¦æ±‚
        
        Args:
            instrument_type: ä»ªè¡¨ç±»å‹
            top_k: è¿”å›ç»“æœæ•°é‡
        
        Returns:
            ææ–™è¦æ±‚æ¡æ¬¾åˆ—è¡¨
        """
        material_queries = [
            f"{instrument_type}å®‰è£…ææ–™",
            f"{instrument_type}ç®¡è·¯ææ–™",
            f"{instrument_type}é˜€é—¨é€‰æ‹©",
            f"{instrument_type}ç”µç¼†è¦æ±‚",
            "ç®¡è·¯ææ–™è¦æ±‚",
            "é˜€é—¨é€‰æ‹©æ ‡å‡†",
            "ç”µç¼†å®‰è£…è¦æ±‚"
        ]
        
        all_results = []
        seen_contents = set()
        
        for query in material_queries:
            results = self.search_related_clauses(query, top_k=2)
            
            for result in results:
                content = result['content']
                if content not in seen_contents and any(keyword in content for keyword in ['ææ–™', 'é˜€é—¨', 'ç”µç¼†', 'ç®¡è·¯']):
                    seen_contents.add(content)
                    result['query'] = query
                    all_results.append(result)
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        all_results.sort(key=lambda x: x['score'], reverse=True)
        
        return all_results[:top_k]
    
    def get_comprehensive_standards(self, instrument_type: str) -> Dict[str, List[Dict]]:
        """
        è·å–æŸä»ªè¡¨ç±»å‹çš„ç»¼åˆå®‰è£…è§„èŒƒä¿¡æ¯
        
        Args:
            instrument_type: ä»ªè¡¨ç±»å‹
        
        Returns:
            åŒ…å«å®‰è£…æ–¹æ³•ã€ææ–™è¦æ±‚ç­‰åˆ†ç±»ä¿¡æ¯çš„å­—å…¸
        """
        result = {
            'instrument_type': instrument_type,
            'installation_methods': [],
            'material_requirements': [],
            'safety_requirements': [],
            'maintenance_requirements': []
        }
        
        # æœç´¢å®‰è£…æ–¹æ³•
        installation_results = self.search_by_instrument_type(instrument_type, top_k=3)
        result['installation_methods'] = installation_results
        
        # æœç´¢ææ–™è¦æ±‚
        material_results = self.search_installation_materials(instrument_type, top_k=3)
        result['material_requirements'] = material_results
        
        # æœç´¢å®‰å…¨è¦æ±‚
        safety_queries = [f"{instrument_type}å®‰å…¨è¦æ±‚", "å®‰å…¨æ³¨æ„äº‹é¡¹", "é˜²æŠ¤è¦æ±‚"]
        for query in safety_queries:
            safety_results = self.search_related_clauses(query, top_k=2)
            for res in safety_results:
                if any(keyword in res['content'] for keyword in ['å®‰å…¨', 'é˜²æŠ¤', 'æ³¨æ„']):
                    result['safety_requirements'].append(res)
                    break
        
        # æœç´¢ç»´æŠ¤è¦æ±‚
        maintenance_queries = [f"{instrument_type}ç»´æŠ¤", "ç»´æŠ¤ä¿å…»", "æ£€ä¿®è¦æ±‚"]
        for query in maintenance_queries:
            maintenance_results = self.search_related_clauses(query, top_k=2)
            for res in maintenance_results:
                if any(keyword in res['content'] for keyword in ['ç»´æŠ¤', 'ä¿å…»', 'æ£€ä¿®']):
                    result['maintenance_requirements'].append(res)
                    break
        
        return result

def match_standard_clause(instrument_type: str, query_type: str = "installation", top_k: int = 5) -> List[str]:
    """
    åŒ¹é…æ ‡å‡†æ¡æ¬¾çš„ä¾¿æ·å‡½æ•°
    
    Args:
        instrument_type: ä»ªè¡¨ç±»å‹
        query_type: æŸ¥è¯¢ç±»å‹ ("installation", "materials", "safety", "maintenance")
        top_k: è¿”å›ç»“æœæ•°é‡
    
    Returns:
        åŒ¹é…çš„æ–‡æœ¬æ®µè½åˆ—è¡¨
    """
    retriever = StandardClauseRetriever()
    
    if query_type == "installation":
        results = retriever.search_by_instrument_type(instrument_type, top_k)
    elif query_type == "materials":
        results = retriever.search_installation_materials(instrument_type, top_k)
    else:
        # è‡ªå®šä¹‰æŸ¥è¯¢
        query = f"{instrument_type}{query_type}"
        results = retriever.search_related_clauses(query, top_k)
    
    # è¿”å›æ–‡æœ¬å†…å®¹åˆ—è¡¨
    return [result['content'] for result in results]

def search_standards_by_keywords(keywords: List[str], top_k: int = 5) -> List[Dict]:
    """
    åŸºäºå…³é”®è¯æœç´¢æ ‡å‡†è§„èŒƒ
    
    Args:
        keywords: å…³é”®è¯åˆ—è¡¨
        top_k: è¿”å›ç»“æœæ•°é‡
    
    Returns:
        æœç´¢ç»“æœåˆ—è¡¨
    """
    retriever = StandardClauseRetriever()
    
    # ç»„åˆå…³é”®è¯ä¸ºæŸ¥è¯¢
    query = " ".join(keywords)
    
    return retriever.search_related_clauses(query, top_k)

def match_standards_for_instruments(instruments_df) -> List[str]:
    """
    ä¸ºä»ªè¡¨DataFrameæ‰¹é‡åŒ¹é…æ ‡å‡†æ¡æ¬¾
    
    Args:
        instruments_df: åŒ…å«ä»ªè¡¨ä¿¡æ¯çš„DataFrameï¼Œéœ€åŒ…å«'ä»ªè¡¨ç±»å‹'åˆ—
    
    Returns:
        åŒ¹é…æ ‡å‡†åˆ—è¡¨ï¼Œä¸è¾“å…¥DataFrameè¡Œå¯¹åº”
    """
    retriever = StandardClauseRetriever()
    matched_standards = []
    
    for _, row in instruments_df.iterrows():
        instrument_type = row.get('ä»ªè¡¨ç±»å‹', 'æœªçŸ¥ä»ªè¡¨')
        
        try:
            # æœç´¢è¯¥ä»ªè¡¨ç±»å‹çš„å®‰è£…è§„èŒƒ
            results = retriever.search_by_instrument_type(instrument_type, top_k=1)
            
            if results:
                # å–æœ€åŒ¹é…çš„æ ‡å‡†æ¡æ¬¾
                best_match = results[0]['content']
                # æˆªå–å‰100å­—ç¬¦ä½œä¸ºç®€è¦æè¿°
                if len(best_match) > 100:
                    best_match = best_match[:100] + "..."
                matched_standards.append(best_match)
            else:
                matched_standards.append("æœªæ‰¾åˆ°åŒ¹é…çš„å®‰è£…æ ‡å‡†")
                
        except Exception as e:
            logger.error(f"åŒ¹é…æ ‡å‡†æ—¶å‡ºé”™ ({instrument_type}): {str(e)}")
            matched_standards.append("æ ‡å‡†åŒ¹é…å¤±è´¥")
    
    return matched_standards

def get_installation_summary(instrument_type: str) -> str:
    """
    è·å–ä»ªè¡¨å®‰è£…è¦æ±‚æ‘˜è¦
    
    Args:
        instrument_type: ä»ªè¡¨ç±»å‹
    
    Returns:
        å®‰è£…è¦æ±‚æ‘˜è¦æ–‡æœ¬
    """
    retriever = StandardClauseRetriever()
    comprehensive_info = retriever.get_comprehensive_standards(instrument_type)
    
    summary_parts = [f"# {instrument_type}å®‰è£…è§„èŒƒæ‘˜è¦\n"]
    
    # å®‰è£…æ–¹æ³•
    if comprehensive_info['installation_methods']:
        summary_parts.append("## å®‰è£…æ–¹æ³•")
        for i, method in enumerate(comprehensive_info['installation_methods'][:2], 1):
            summary_parts.append(f"{i}. {method['content'][:200]}...")
        summary_parts.append("")
    
    # ææ–™è¦æ±‚
    if comprehensive_info['material_requirements']:
        summary_parts.append("## ææ–™è¦æ±‚")
        for i, material in enumerate(comprehensive_info['material_requirements'][:2], 1):
            summary_parts.append(f"{i}. {material['content'][:200]}...")
        summary_parts.append("")
    
    # å®‰å…¨è¦æ±‚
    if comprehensive_info['safety_requirements']:
        summary_parts.append("## å®‰å…¨è¦æ±‚")
        for i, safety in enumerate(comprehensive_info['safety_requirements'][:1], 1):
            summary_parts.append(f"{i}. {safety['content'][:200]}...")
    
    return "\n".join(summary_parts)

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logging.basicConfig(level=logging.INFO)
    
    # é¦–å…ˆç¡®ä¿æœ‰ç´¢å¼•æ–‡ä»¶ï¼ˆå¦‚æœæ²¡æœ‰åˆ™æ„å»ºï¼‰
    from tools.build_index import create_sample_standards_data, build_index_from_files
    
    if not os.path.exists(FAISS_INDEX_PATH):
        print("ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»ºç¤ºä¾‹ç´¢å¼•...")
        sample_file = create_sample_standards_data()
        build_index_from_files([sample_file])
    
    # æµ‹è¯•æ£€ç´¢åŠŸèƒ½
    retriever = StandardClauseRetriever()
    
    test_instrument_types = ["çƒ­ç”µå¶", "å‹åŠ›è¡¨", "æµé‡è®¡"]
    
    for instrument_type in test_instrument_types:
        print(f"\n{'='*50}")
        print(f"æµ‹è¯•æ£€ç´¢: {instrument_type}")
        print('='*50)
        
        # æµ‹è¯•åŸºæœ¬æ£€ç´¢
        results = retriever.search_by_instrument_type(instrument_type, top_k=2)
        print(f"\n{instrument_type}ç›¸å…³è§„èŒƒ ({len(results)}æ¡):")
        for i, result in enumerate(results, 1):
            print(f"{i}. ç›¸ä¼¼åº¦: {result['score']:.3f}")
            print(f"   å†…å®¹: {result['content'][:100]}...")
        
        # æµ‹è¯•ç»¼åˆä¿¡æ¯æ£€ç´¢
        comprehensive = retriever.get_comprehensive_standards(instrument_type)
        print(f"\n{instrument_type}ç»¼åˆä¿¡æ¯:")
        print(f"- å®‰è£…æ–¹æ³•: {len(comprehensive['installation_methods'])}æ¡")
        print(f"- ææ–™è¦æ±‚: {len(comprehensive['material_requirements'])}æ¡")
        print(f"- å®‰å…¨è¦æ±‚: {len(comprehensive['safety_requirements'])}æ¡")
    
    print("\nå®‰è£…è§„èŒƒæ£€ç´¢å·¥å…·å·²å°±ç»ª") 